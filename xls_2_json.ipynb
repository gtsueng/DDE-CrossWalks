{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a738804f",
   "metadata": {},
   "source": [
    "## XLS To Xwalk converter\n",
    "\n",
    "This script generates a crosswalks:MetadataCrossWalk schema-compliant JSONLD file.\n",
    "\n",
    "1. Assumes mapping happens between only two schemas (ie - only one mapping)\n",
    "2. Note that xlsx support is spotty due to library dependencies changing. To ensure the script runs, save the xlsx file as an xls file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50c438ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_excel\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b677810",
   "metadata": {},
   "source": [
    "#### Excel template sheet info\n",
    "\n",
    "* **metaInfo**: Information about the crosswalk itself. For example, 'author' refers to the authors of the crosswalk, not the authors of the schemas evaluated/mapped in the crosswalk.\n",
    "* **authorInfo**: The authors of the crosswalk. This sheet is used to create an array of Person or Organization objects\n",
    "* **fundingInfo**: Funding information for the development of the crosswalk.\n",
    "* **schemaObjects**: Information about the two schema being compared/mapped.\n",
    " * **schemaOriginObject**: The subject schema\n",
    " * **schemaTargetObject**: The object schema\n",
    " * **schemaUsageObject**: Schemas or crosswalks that uses this metadata crosswalk or mapping\n",
    "* **nestedProps**: Information for other nested objects which are the expected values of properties of the MetadataCrosswalk\n",
    "* **propertyList**: The sheet actually showing the mapping of the properties from one schema to the next. Column names should reference the schema, and additional information on \n",
    "\n",
    "For individual properties with multiple ranges or domains included, each range or domainIncluded should be delimited by a comma only.\n",
    "\n",
    "Because different schemas may nest properties differently, all properties should be listed and mapped based on the nesting within the class to be mapped. Nested properties that can be mapped should be denoted using dot notation: eg-parent_object.property. Properties belonging to classes that are referenced but not part of the parent class should be included based on the reference property. For example, the property 'doi' in the NIAID schema belongs to the ScholarlyArticle class, not the Dataset class; however, it will be referenced in the Dataset class using the 'citation' property. Hence, it should be included/mapped as 'citation.doi'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b4c66fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_list(contextdf):\n",
    "    context_dict = {}\n",
    "    for i in range(len(contextdf)):\n",
    "        contextdf.fillna('null',inplace=True)\n",
    "        tmpnamespace = contextdf.iloc[i]['namespace']\n",
    "        tmpuri = contextdf.iloc[i]['@context']\n",
    "        context_dict[str(tmpnamespace)]=str(tmpuri)\n",
    "    clean_context = dict((k, v) for k, v in context_dict.items() if v!='null')\n",
    "    if \"schema\" not in list(clean_context.keys()):\n",
    "        clean_context[\"schema\"] = \"https://schema.org/\"\n",
    "    if \"owl\" not in list(clean_context.keys()):\n",
    "        clean_context[\"owl\"] = \"http://www.w3.org/2002/07/owl#\"\n",
    "    if \"rdf\" not in list(clean_context.keys()):\n",
    "        clean_context[\"rdf\"] = \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n",
    "    if \"rdfs\" not in list(clean_context.keys()):\n",
    "        clean_context[\"rdfs\"] = \"http://www.w3.org/2000/01/rdf-schema#\"\n",
    "    return clean_context\n",
    "\n",
    "def clean_citations(schemaObject):\n",
    "    citationdf = schemaObject[['citation.@type','citation.name','citation.url']].copy()\n",
    "    citationdf.rename(columns={'citation.@type':'@type','citation.name':'name','citation.url':'url'},inplace=True)\n",
    "    citejson = citationdf.to_dict(orient='records')\n",
    "    schemaObject['citation'] = [x for x in citejson]\n",
    "    schemaObject.drop(columns = ['citation.@type','citation.name','citation.url'], axis=1,inplace=True)\n",
    "    return schemaObject\n",
    "\n",
    "def load_authors(data_file):\n",
    "    author_info = read_excel(data_file,sheet_name='authorInfo',header=0,index_col=None)\n",
    "    author_object = author_info.to_dict(orient=\"records\")\n",
    "    return author_object\n",
    "\n",
    "def load_funding(data_file):\n",
    "    funding_info = read_excel(data_file,sheet_name='fundingInfo',header=0,index_col=None)\n",
    "    if len(funding_info)>0:\n",
    "        funder_info = funding_info[['funder.@type','funder.name']].copy()\n",
    "        funder_info.rename(columns={'funder.@type':'@type','funder.name':'name'}, inplace=True)\n",
    "        funder_dict_list = funder_info.to_dict(orient=\"records\")\n",
    "        funding = funding_info[['@type','identifier']].copy()\n",
    "        funding['funder'] = [x for x in funder_dict_list]\n",
    "        fundingdict = funding.to_dict(orient=\"records\")\n",
    "    else:\n",
    "        fundingdict = {}\n",
    "    return fundingdict\n",
    "\n",
    "def load_schema_objects(data_file):\n",
    "    schemaObjects = read_excel(data_file,sheet_name='schemaObjects',header=0,index_col=None)\n",
    "    schemaObjects['version'] = schemaObjects.apply(lambda row: clean_up_dates(row['version']), axis=1)\n",
    "    schemaContext = schemaObjects[['namespace','@context']].copy()\n",
    "    context_dict = generate_context_list(schemaContext)\n",
    "    schemaObjects = clean_citations(schemaObjects)\n",
    "    schemaOriginObjects = schemaObjects.loc[schemaObjects['objectType']=='schemaOriginObject'].copy()\n",
    "    schemaTargetObjects = schemaObjects.loc[schemaObjects['objectType']=='schemaTargetObject'].copy()\n",
    "    schemaOriginObjects.drop(['namespace','@context','objectType'],axis=1,inplace=True)\n",
    "    schemaTargetObjects.drop(['namespace','@context','objectType'],axis=1,inplace=True)\n",
    "    schemaOriginList = schemaOriginObjects.to_dict(orient=\"records\")\n",
    "    schemaTargetList = schemaTargetObjects.to_dict(orient=\"records\")\n",
    "    try:\n",
    "        schemaUsageObjects = schemaObjects.loc[schemaObjects['objectType']=='schemaUsageObject'].copy()    \n",
    "        schemaUsageObjects.drop(['namespace','@context','objectType'],axis=1,inplace=True)\n",
    "        schemaUsageList = schemaUsageObjects.to_dict(orient=\"records\")\n",
    "    except:\n",
    "        schemaUsageList = None\n",
    "    idlist = schemaObjects['identifier'].unique().tolist()\n",
    "    return schemaOriginList, schemaTargetList, schemaUsageList, context_dict, idlist\n",
    "\n",
    "def merge_schema_objects(schemaOriginList,schemaTargetList):\n",
    "    schemalist = []\n",
    "    for x in schemaOriginList:\n",
    "        schemalist.append(x)\n",
    "    for y in schemaTargetList:\n",
    "        schemalist.append(y)\n",
    "    return schemalist\n",
    "\n",
    "def load_schema_usage_objects(schemaUsageList):\n",
    "    schemalist = []\n",
    "    for z in schemaUsageList:\n",
    "        schemalist.append(z)\n",
    "    return schemalist\n",
    "    \n",
    "def clean_up_dates(propvalue):\n",
    "    if type(propvalue)==str:\n",
    "        tmppropvalue = propvalue.strip('\"')\n",
    "        cleanpropvalue = tmppropvalue.strip(\"'\")\n",
    "    elif isinstance(propvalue,datetime):\n",
    "        cleanpropvalue = datetime.strftime(propvalue,\"%Y-%m-%d\")\n",
    "    else:\n",
    "        cleanpropvalue = propvalue\n",
    "    return cleanpropvalue\n",
    "\n",
    "def parse_nestedProps(data_file):\n",
    "    nestedProps = read_excel(data_file,sheet_name='nestedProps',header=0,index_col=None)\n",
    "    nestedProps.fillna(\"null\",inplace=True)\n",
    "    proplist = nestedProps['property'].unique().tolist()\n",
    "    propdict = {}\n",
    "    for eachprop in proplist:\n",
    "        tmpdf = nestedProps.loc[nestedProps['property']==eachprop].copy()\n",
    "        tmpdf.drop('property',axis=1,inplace=True)\n",
    "        tmpdict = tmpdf.to_dict(orient=\"records\")\n",
    "        cleandict = []\n",
    "        for eachdict in tmpdict:\n",
    "            cleandict.append(dict((k, v) for k, v in eachdict.items() if v!=\"null\"))\n",
    "        propdict[eachprop] = cleandict\n",
    "    return propdict\n",
    "\n",
    "#### value string formatting functions\n",
    "def format_iri_as_id(example_iri):\n",
    "    iri_list = example_iri.split(',')\n",
    "    tmplist = []\n",
    "    for each_iri in iri_list:\n",
    "        iri_dict = {\"@id\":each_iri}\n",
    "        tmplist.append(iri_dict)\n",
    "    return tmplist   \n",
    "\n",
    "def get_last_element(nestedname):\n",
    "    namelist = nestedname.split('.')\n",
    "    if len(namelist)>1:\n",
    "        last_element = namelist[-1]\n",
    "    if len(namelist)==1:\n",
    "        last_element = namelist[0]\n",
    "    if len(namelist)==0:\n",
    "        last_element = nestedname\n",
    "    return last_element\n",
    "\n",
    "#### property functions\n",
    "def add_type(propertydf):\n",
    "    propertydf['@type'] = \"schema:Property\"\n",
    "    return propertydf\n",
    "\n",
    "def cleanup_domain_range(propertydf):\n",
    "    try:\n",
    "        propertydf['rangeIncludes'] = propertydf.apply(lambda row: format_iri_as_id(row['rangeIncludes']), axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        propertydf['domainIncludes'] = propertydf.apply(lambda row: format_iri_as_id(row['domainIncludes']), axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    return propertydf\n",
    "\n",
    "def idlist_to_renamedf(idlist):\n",
    "    renamedf = {}\n",
    "    for eachid in idlist:\n",
    "        renamedf[eachid] = 'property'\n",
    "    return renamedf\n",
    "\n",
    "def generate_isPartOf_info(propertydf,idlist):\n",
    "    partid = [col for col in propertydf.columns if col in idlist]\n",
    "    tmpdict = {'@id': partid[0]}\n",
    "    return tmpdict\n",
    "\n",
    "def clean_up_source_id(propertydf,idlist):\n",
    "    partdict = generate_isPartOf_info(propertydf,idlist)\n",
    "    renamedf = idlist_to_renamedf(idlist)\n",
    "    propertydf.rename(columns=renamedf,inplace=True)\n",
    "    propertydf['isPartOf'] = [partdict for x in propertydf['property']]\n",
    "    return propertydf\n",
    "\n",
    "def clean_up_prop_names(propertydf):\n",
    "    propertydf.rename(columns = {'property':'nestedName'},inplace=True)\n",
    "    propertydf['name'] = propertydf.apply(lambda row: get_last_element(row['nestedName']), axis=1)\n",
    "    return propertydf\n",
    "\n",
    "def clean_up_props(propertydf,idlist):\n",
    "    propertydf = clean_up_source_id(propertydf,idlist)\n",
    "    propertydf = clean_up_prop_names(propertydf)\n",
    "    propertydf = cleanup_domain_range(propertydf)\n",
    "    return propertydf\n",
    "\n",
    "    \n",
    "def generate_prop_included(data_file,idlist):\n",
    "    proplist = read_excel(data_file,sheet_name='propertyList',header=0,index_col=None)\n",
    "    proplist.dropna(axis=1, how='all', inplace=True)\n",
    "    same_cols = [col for col in proplist.columns if 'sameAs' in col]\n",
    "    source_cols = [col for col in proplist.columns if 'sameAs' not in col]\n",
    "    sourcedf = proplist[source_cols].copy()\n",
    "    sourcedf = clean_up_props(sourcedf,idlist)\n",
    "    samedf = proplist[same_cols].copy()\n",
    "    samedf.rename(columns=lambda s: s.replace(\"sameAs.\", \"\"), inplace=True)\n",
    "    samedf = clean_up_props(samedf,idlist)\n",
    "    samedict = samedf.to_dict(orient=\"records\")\n",
    "    sourcedf['sameAs'] = samedict\n",
    "    propdictlist = sourcedf.to_dict(orient=\"records\")\n",
    "    return propdictlist\n",
    "    \n",
    "\n",
    "def convert_xls_xwalk(data_file):\n",
    "    author_object = load_authors(data_file)\n",
    "    funding_object = load_funding(data_file)\n",
    "    schemaOriginList, schemaTargetList, schemaUsageList, context_dict, idlist = load_schema_objects(data_file)\n",
    "    propdict = parse_nestedProps(data_file)\n",
    "    includedprops = generate_prop_included(data_file,idlist)\n",
    "    xwalkmeta = read_excel(data_file,sheet_name='metainfo',header=0,index_col=0)\n",
    "    xwalkmeta.dropna(inplace=True)\n",
    "    xwalkdict = xwalkmeta.to_dict()\n",
    "    xwalkclean = OrderedDict(xwalkdict['value'])\n",
    "    xwalkclean['@context'] = context_dict\n",
    "    xwalkclean['@type'] = 'crosswalks:MetadataCrosswalk'\n",
    "    xwalkclean['author'] = author_object\n",
    "    if len(funding_object)>0:\n",
    "        xwalkclean['funding'] = funding_object\n",
    "    xwalkclean['hasPart'] = merge_schema_objects(schemaOriginList,schemaTargetList)\n",
    "    xwalkclean['datePublished'] = clean_up_dates(xwalkclean['datePublished'])\n",
    "    xwalkclean['dateModified'] = clean_up_dates(xwalkclean['dateModified'])\n",
    "    try:\n",
    "        xwalkclean['isBasedOn'] = propdict['isBasedOn']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        xwalkclean['isBasisFor'] = propdict['isBasisFor']\n",
    "    except:\n",
    "        pass\n",
    "    xwalkclean['includesProperty'] = includedprops\n",
    "    if schemaUsageList != None:\n",
    "        xwalkclean['isPartOf'] = load_schema_usage_objects(schemaUsageList)\n",
    "    return xwalkclean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b390c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main\n",
    "\n",
    "script_path = ''\n",
    "data_path = os.path.join(script_path,'crosswalks')\n",
    "export_path = os.path.join(script_path,'jsoncrosswalks')\n",
    "#data_file = os.path.join(data_path,'vuepathdb.xls')\n",
    "#export_file = os.path.join(export_path,'vuepathdb.json')\n",
    "data_files = os.listdir(data_path)\n",
    "\n",
    "for filename in data_files:\n",
    "    data_file = os.path.join(data_path,filename)\n",
    "    export_file = os.path.join(export_path,filename.replace('xls','json'))\n",
    "    try:\n",
    "        xwalkjson = convert_xls_xwalk(data_file)\n",
    "        with open(export_file,'w') as outfile:\n",
    "            jsonfile = json.dumps(xwalkjson, indent=2)\n",
    "            outfile.write(jsonfile)\n",
    "    except:\n",
    "        print(\"failed to convert: \",filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e4594c",
   "metadata": {},
   "source": [
    "### Validate the json output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea2e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonschema\n",
    "from jsonschema import validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53945366",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the json schema\n",
    "\n",
    "script_path = ''\n",
    "data_path = os.path.join(script_path,'crosswalks')\n",
    "export_path = os.path.join(script_path,'jsoncrosswalks')\n",
    "#data_file = os.path.join(data_path,'vuepathdb.xls')\n",
    "#export_file = os.path.join(export_path,'vuepathdb.json')\n",
    "schema_path = os.path.join(script_path,'schema')\n",
    "schema_file = os.path.join(schema_path,'MetadataCrossWalk.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(export_file,'r') as inputfile:\n",
    "    jsondata = json.load(inputfile)\n",
    "\n",
    "with open(schema_file,'r') as schemainput:\n",
    "    testschema = json.load(schemainput)\n",
    "\n",
    "validate(testschema, schema=jsondata)\n",
    "validate(testschema['@graph'][0]['$validation'], schema=jsondata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdebcac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "daa2871f",
   "metadata": {},
   "source": [
    "### Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ca664",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in data_files:\n",
    "    data_file = os.path.join(data_path,filename)\n",
    "    export_file = os.path.join(export_path,filename.replace('xls','json'))\n",
    "    xwalkjson = convert_xls_xwalk(data_file)\n",
    "#    with open(export_file,'w') as outfile:\n",
    "#        jsonfile = json.dumps(xwalkjson, indent=2)\n",
    "#        outfile.write(jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1986bfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_object = load_authors(data_file)\n",
    "#print(author_object[0])\n",
    "funding_object = load_funding(data_file)\n",
    "#print(funding_object)\n",
    "schemaOriginList, schemaTargetList, schemaUsageList, context_dict, idlist = load_schema_objects(data_file)\n",
    "#print(schemaOriginList)\n",
    "propdict = parse_nestedProps(data_file)\n",
    "#print(propdict)\n",
    "includedprops = generate_prop_included(data_file,idlist)\n",
    "#print(includedprops[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666bef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "proplist = read_excel(data_file,sheet_name='propertyList',header=0,index_col=None)\n",
    "proplist.dropna(axis=1, how='all', inplace=True)\n",
    "same_cols = [col for col in proplist.columns if 'sameAs' in col]\n",
    "source_cols = [col for col in proplist.columns if 'sameAs' not in col]\n",
    "sourcedf = proplist[source_cols].copy()\n",
    "partid = [col for col in sourcedf.columns if col in idlist]\n",
    "print(sourcedf.head(n=2))\n",
    "#tmpdict = {'@id': partid[0]}\n",
    "#sourcedf = clean_up_props(sourcedf,idlist)\n",
    "#samedf = proplist[same_cols].copy()\n",
    "#samedf.rename(columns=lambda s: s.replace(\"sameAs.\", \"\"), inplace=True)\n",
    "#samedf = clean_up_props(samedf,idlist)\n",
    "#samedict = samedf.to_dict(orient=\"records\")\n",
    "#sourcedf['sameAs'] = samedict\n",
    "#propdictlist = sourcedf.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2857cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = ''\n",
    "data_path = os.path.join(script_path,'crosswalks')\n",
    "export_path = os.path.join(script_path,'jsoncrosswalks')\n",
    "#data_file = os.path.join(data_path,'vuepathdb.xls')\n",
    "#export_file = os.path.join(export_path,'vuepathdb.json')\n",
    "data_files = os.listdir(data_path)\n",
    "\n",
    "data_file = os.path.join(data_path,data_files[0])\n",
    "schemaOriginList, schemaTargetList, schemaUsageList, context_dict, idlist = load_schema_objects(data_file)\n",
    "schemaList = merge_schema_objects(schemaOriginList,schemaTargetList)\n",
    "print(schemaList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3111ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

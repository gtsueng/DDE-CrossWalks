{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0473c5d",
   "metadata": {},
   "source": [
    "## Google spreadsheet crosswalk downloader\n",
    "\n",
    "This notebook helps maintain a list of google spreadsheet crosswalks that are downloaded as xlsx files and converted for upload in json-ld format. This makes it easier for collaboratively edited/maintained crosswalk files to be updated.\n",
    "\n",
    "This notebook includes functions that:\n",
    "\n",
    "0. Enable reading of google spreadsheets similar to xlsx file\n",
    "1. Create list of crosswalks\n",
    "2. Enable checking for google spreadsheet in list of crosswalks and adding it if it's not there\n",
    "3. Download and save google spreadsheet as an xlsx file\n",
    "4. Create GitHub issue template\n",
    "5. Create script for maintaining list (that can run in conjunction with a GitHub pull request template and GitHub action)\n",
    "  * See crosswalks_maintenance notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09b8b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gtsueng\\Anaconda3\\envs\\outbreak\\DDE-CrossWalks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import openpyxl\n",
    "from io import BytesIO as BytesIO\n",
    "\n",
    "nb_path = os.getcwd()\n",
    "parent_path = os.path.dirname(nb_path)\n",
    "tempfiles = os.path.join(parent_path,'tempfiles')\n",
    "print(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a4e354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Handle spreadsheets from google\n",
    "def parse_g_sheet_url(gsheeturl):\n",
    "    baseurl = 'https://docs.google.com/spreadsheets/d/'\n",
    "    tmpurl = gsheeturl.replace(baseurl,'')\n",
    "    tmpurlcontent = tmpurl.split('/')\n",
    "    spreadsheetId = tmpurlcontent[0]\n",
    "    return spreadsheetId\n",
    "\n",
    "def load_g_cred(parent_path):\n",
    "    from pydrive2.auth import GoogleAuth\n",
    "    from pydrive2.drive import GoogleDrive\n",
    "    from pydrive2.auth import ServiceAccountCredentials\n",
    "    gauth = GoogleAuth()\n",
    "    scope = ['https://www.googleapis.com/auth/drive']\n",
    "    gauth.credentials = ServiceAccountCredentials.from_json_keyfile_name(os.path.join(parent_path,'credentials.json'), scope)\n",
    "    return gauth\n",
    "\n",
    "def load_g_sheet_data(parent_path, gsheeturl):\n",
    "    gauth = load_g_cred(parent_path)\n",
    "    spreadsheetID = parse_g_sheet_url(gsheeturl)\n",
    "    url = f\"https://docs.google.com/spreadsheets/export?id={spreadsheetID}&exportFormat=xlsx\"\n",
    "    res = requests.get(url, headers={\"Authorization\": \"Bearer \" + str(gauth.attr['credentials'].access_token)})\n",
    "    data_file = res.content\n",
    "    return data_file\n",
    "\n",
    "#### Handle spreadsheets saved in GitHub\n",
    "def load_github_data(githuburl):\n",
    "    url = f\"{githuburl}?raw=true\"\n",
    "    res = requests.get(url)\n",
    "    data_file = res.content\n",
    "    return data_file\n",
    "\n",
    "#### Handle spreadsheets saved elsewhere\n",
    "def load_xls_data(otherurl):\n",
    "    res = requests.get(url)\n",
    "    data_file = res.content\n",
    "    return data_File\n",
    "\n",
    "#### Pull basic metadata from spreadsheet\n",
    "def get_xwalk_meta(parent_path, inputurl):\n",
    "    if 'github' in inputurl:\n",
    "        data_file = load_github_data(inputurl)\n",
    "        xwalk_dict = {'url':inputurl, 'urlType':'GitHub'}\n",
    "    elif 'google' in inputurl:\n",
    "        data_file = load_g_sheet_data(parent_path, inputurl)\n",
    "        xwalk_dict = {'url':inputurl, 'urlType':'Gsheet'}\n",
    "    else:\n",
    "        try:\n",
    "            data_file = load_xls_data(otherurl)\n",
    "        except:\n",
    "            data_file = None\n",
    "        xwalk_dict = {'url':inputurl, 'urlType':'Other'}\n",
    "    if data_file != None:\n",
    "        try:\n",
    "            try:\n",
    "                values = pd.read_excel(data_file,sheet_name='metainfo',header=0,index_col=None)\n",
    "            except:\n",
    "                data_stream = BytesIO(data_file)\n",
    "                values = pd.read_excel(data_stream,sheet_name='metainfo',header=0,index_col=None)\n",
    "        except:\n",
    "            try:\n",
    "                values = pd.read_excel(data_file,sheet_name='metainfo',header=0,index_col=None,engine=\"openpyxl\")\n",
    "            except:\n",
    "                data_stream = BytesIO(data_file)\n",
    "                values = pd.read_excel(data_stream,sheet_name='metainfo',header=0,index_col=None,engine=\"openpyxl\")                \n",
    "        fileid = values['value'].loc[values['property']=='identifier']\n",
    "        version = values['value'].loc[values['property']=='dateModified']\n",
    "        xwalk_dict['identifier'] = fileid.iloc[0]\n",
    "        xwalk_dict['version'] = version.iloc[0]\n",
    "    return xwalk_dict, data_file\n",
    "\n",
    "\n",
    "def download_spreadsheet(parent_path,url):\n",
    "    if 'xlsx' in url:\n",
    "        extension = '.xlsx'\n",
    "    elif 'google' in url:\n",
    "        extension = '.xlsx'\n",
    "    else:\n",
    "        extension = '.xls'\n",
    "    xwalk_dict, data_file = get_xwalk_meta(parent_path, url)\n",
    "    identifier = xwalk_dict['identifier']\n",
    "    if data_file != None:\n",
    "        with open(os.path.join(parent_path,'crosswalks',f\"{identifier}{extension}\"), 'wb') as output:\n",
    "            output.write(data_file)\n",
    "    else:\n",
    "        print('unable to parse data from provided url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac403359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_version(parent_path,data_file):\n",
    "    tmpjson = json.load(open(os.path.join(parent_path,'jsoncrosswalks',data_file),'rb'))\n",
    "    dateModified = tmpjson['dateModified']\n",
    "    jsonversion = datetime.strptime(dateModified,\"%Y-%m-%d\")\n",
    "    return jsonversion  \n",
    "\n",
    "def get_xls_version(data_file):\n",
    "    try:\n",
    "        xwalkmeta = pd.read_excel(data_file,sheet_name='metainfo',header=0,index_col=0)\n",
    "    except:\n",
    "        xwalkmeta = pd.read_excel(data_file,sheet_name='metainfo',header=0,index_col=0,engine=\"openpyxl\")\n",
    "    xwalkdict = xwalkmeta.to_dict()\n",
    "    dateModified = xwalkdict['value']['dateModified']\n",
    "    if isinstance(dateModified,str):\n",
    "        xls_version = datetime.strptime(dateModified.replace('\"','').replace(\"'\",\"\"),\"%Y-%m-%d\")\n",
    "    else:\n",
    "        xls_version = dateModified\n",
    "    return xls_version\n",
    "\n",
    "def compare_versions(version1,version2):\n",
    "    if version1 > version2:\n",
    "        newer = version1\n",
    "    else: #otherwise version 2 is either newer or the same, so just keep it\n",
    "        newer = version2\n",
    "    return newer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a10e5990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Check if the json_crosswalks folder is up-to-date\n",
    "#from src.xls_to_json import *\n",
    "\n",
    "def check_crosswalks_conversion(parent_path):\n",
    "    crosswalks_path = os.path.join(parent_path,'crosswalks')\n",
    "    json_crosswalks_path = os.path.join(parent_path,'jsoncrosswalks')\n",
    "    saved_crosswalks_list = os.listdir(crosswalks_path)\n",
    "    json_crosswalks_list = os.listdir(json_crosswalks_path)\n",
    "    ## For each item in crosswalks df\n",
    "    for eachfile in saved_crosswalks_list:\n",
    "        filename = eachfile.replace('.xls','.json').replace('.xlsx','.json')\n",
    "     ### Check if the file already exists\n",
    "        if filename in json_crosswalks_list:\n",
    "            jsonversion = get_json_version(parent_path,filename)\n",
    "            xlsversion = get_xls_version(os.path.join(parent_path,'crosswalks',eachfile))\n",
    "            ### If it does, check if the version is up-to-date\n",
    "            if jsonversion < xlsversion:\n",
    "                ### If the jsonversion is older than the xls version, run the conversion\n",
    "                convert_a_crosswalk(crosswalks_path,eachfile,json_crosswalks_path)\n",
    "        ### If it doesn't exist, run the conversion             \n",
    "        else:\n",
    "            convert_a_crosswalk(crosswalks_path,eachfile,json_crosswalks_path) \n",
    "            \n",
    "\n",
    "#### Check if items in crosswalks list are in the crosswalks folder\n",
    "def check_crosswalks_list(parent_path):\n",
    "    try:\n",
    "        crosswalksdf = pd.read_csv(os.path.join(parent_path,'crosswalkslist.txt'),delimiter='\\t',header=0, parse_dates=['version'])\n",
    "    except:\n",
    "        crosswalksdf = pd.read_csv(os.path.join(parent_path,'crosswalkslist.txt'),delimiter='\\t',header=0)\n",
    "    crosswalks_path = os.path.join(parent_path,'crosswalks')\n",
    "    saved_crosswalks_list = os.listdir(crosswalks_path)\n",
    "    ## For each item in crosswalks df\n",
    "    crosswalk_list = crosswalksdf['identifier'].tolist()\n",
    "    for identifier in crosswalk_list:\n",
    "        tmp = crosswalksdf.loc[crosswalksdf['identifier']==identifier]\n",
    "        txtversion = tmp.iloc[0]['version']\n",
    "        txturl = tmp.iloc[0]['url']\n",
    "        ### Check if the file already exists\n",
    "        if (f\"{identifier}.xls\" in saved_crosswalks_list) or (f\"{identifier}.xlsx\" in saved_crosswalks_list):\n",
    "            ### If it does, check if the version is up-to-date\n",
    "            try:\n",
    "                xlsversion = get_xls_version(os.path.join(parent_path,'crosswalks',f\"{identifier}.xls\"))\n",
    "            except:\n",
    "                xlsversion = get_xls_version(os.path.join(parent_path,'crosswalks',f\"{identifier}.xlsx\"))                \n",
    "            newer = compare_versions(txtversion,xlsversion)\n",
    "            ## if the one listed in the textfile is newer, download it\n",
    "            if newer == txtversion:\n",
    "                download_spreadsheet(parent_path,txturl)\n",
    "        else:\n",
    "            ### If it doesn't exist or is not up-to-date, download it\n",
    "            download_spreadsheet(parent_path,txturl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75675ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Functions for GitHub issue parsing\n",
    "\n",
    "## Double-check to ensure it's a crosswalk submission\n",
    "def check_status(eachissue):\n",
    "    if eachissue['state'] == 'open':\n",
    "        update_flag = True\n",
    "    else:\n",
    "        update_flag = False\n",
    "    return update_flag\n",
    "\n",
    "def check_labels(eachissue):\n",
    "    labels = []\n",
    "    for eachlabel in eachissue['labels']:\n",
    "        labels.append(eachlabel['name'])\n",
    "    if 'crosswalk submission' in labels:\n",
    "        label_check = True\n",
    "    else:\n",
    "        label_check = False\n",
    "    return label_check\n",
    "\n",
    "## Parse a mapping submitted via GitHub issue form\n",
    "def parse_mapping_submission(eachissue):\n",
    "    md_result = eachissue['body']\n",
    "    no_space = md_result.replace('\\n\\n','|')\n",
    "    to_parse = f\"[*|{no_space}|*]\"\n",
    "    clean_outer = to_parse.replace('*|### ','{\"').replace('|*','\"}')\n",
    "    clean_inner = clean_outer.replace('|### ','\",\\n\"')\n",
    "    replace_keys = clean_inner.replace('|','\":\"')\n",
    "    ditch_list = replace_keys.replace('[','').replace(']','')\n",
    "    dict_result = json.loads(ditch_list)\n",
    "    dict_result['version'] = datetime.strptime(dict_result['version'],'%m/%d/%Y')\n",
    "    try:\n",
    "        dict_result.pop('Contact Details')\n",
    "    except:\n",
    "        pass\n",
    "    return dict_result\n",
    "\n",
    "## Update a list based on a GitHub issue\n",
    "def check_an_issue(parent_path,eachissue,test=False):\n",
    "    label_check = check_labels(eachissue)\n",
    "    update_flag = check_status(eachissue)\n",
    "    if (label_check == True) and (update_flag == True):\n",
    "        try:\n",
    "            dict_result = parse_mapping_submission(eachissue)\n",
    "            parse_success = True\n",
    "        except:\n",
    "            dict_result = {}\n",
    "            parse_success = False\n",
    "    else:\n",
    "        parse_success = False\n",
    "    ## If an issue was successfully parsed, check if it's already in the csv file\n",
    "    if parse_success == True:\n",
    "        try:\n",
    "            crosswalklist = pd.read_csv(os.path.join(parent_path,'crosswalkslist.txt'),delimiter='\\t',header=0,parse_dates=['version'])\n",
    "        except:\n",
    "            crosswalklist = pd.read_csv(os.path.join(parent_path,'crosswalkslist.txt'),delimiter='\\t',header=0)\n",
    "\n",
    "        all_crosswalks = crosswalklist['identifier'].tolist()\n",
    "        ## Is the crosswalk already in the list?\n",
    "        if dict_result['identifier'] in all_crosswalks:\n",
    "            ## if it is, which version is newer?\n",
    "            tmpdf = crosswalklist.loc[crosswalklist['identifier'] == dict_result['identifier']]\n",
    "            prevdf = crosswalklist.loc[crosswalklist['identifier'] != dict_result['identifier']]\n",
    "            listversion = tmpdf.iloc[0]['version']\n",
    "            issueversion = dict_result['version']\n",
    "            if issueversion > listversion:\n",
    "                ## If the version in the issue is newer than the version in the list, update the list\n",
    "                issuedf = pd.DataFrame([dict_result])\n",
    "                crosswalklist = pd.concat((prevdf,issuedf))\n",
    "                print('file updated')\n",
    "            else:\n",
    "                print('issue version is older')\n",
    "        else:\n",
    "            #print(dict_result[\"identifier\"],\" not yet in: \",all_crosswalks, \", now adding it\")\n",
    "            issuedf = pd.DataFrame([dict_result])\n",
    "            crosswalklist = pd.concat((crosswalklist,issuedf),ignore_index=True)\n",
    "            print(\"crosswalklist updated\")\n",
    "        if test == False:\n",
    "            crosswalklist.to_csv(os.path.join(parent_path,'crosswalkslist.txt'),sep='\\t',header=True)\n",
    "        else:\n",
    "            print('test completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1214cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_repo(REPO, PERSONAL_TOKEN,parent_path,test=False):\n",
    "    i = 0\n",
    "    while i < len(REPO):\n",
    "        headers = {'Authorization': 'token %s' % PERSONAL_TOKEN }\n",
    "        params_payload = { 'state' : 'open', 'labels' : 'crosswalk submission' , 'sort' : 'updated'} \n",
    "        ISSUES_FOR_REPO_URL = 'https://api.github.com/repos/%s/issues' % REPO[i]\n",
    "        r = requests.get(ISSUES_FOR_REPO_URL, params=params_payload, headers=headers) \n",
    "        repo_issues = json.loads(r.text)\n",
    "        for eachissue in repo_issues:\n",
    "            check_an_issue(parent_path,eachissue,test)               \n",
    "        # Check for more pages using the 'Link' header\n",
    "        if 'Link' in r.headers:\n",
    "            while check == True:\n",
    "                # Create overview regarding the different Links, usually previous, first, last and next\n",
    "                data = {}\n",
    "                for links in r.headers['Link'].split(\",\"):\n",
    "                    raw = links.split(\";\")\n",
    "                    data[raw[1][6:6+4]] = raw[0].strip()\n",
    "\n",
    "                if \"next\" in data:\n",
    "                    newlink = data[\"next\"][1:-1]\n",
    "                    r = requests.get(newlink, headers=headers)\n",
    "                    print(\"Now processing page: \" + newlink)\n",
    "                    write_issues(r)\n",
    "                    if data[\"next\"] == data[\"last\"]:\n",
    "                        check = False\n",
    "                        print(\"Done with Repository: \" + REPO[i])\n",
    "                else:\n",
    "                    check = False\n",
    "                    print(\"Done with Repository: \" + REPO[i])\n",
    "        else:\n",
    "            print(\"Done with Repository: \" + REPO[i])\n",
    "\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5650e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with Repository: gtsueng/DDE-CrossWalks\n"
     ]
    }
   ],
   "source": [
    "###### Check GitHub issues for crosswalk submissions to be processed\n",
    "#### Based on https://gist.github.com/mmoelli/91e8fafbfbabf7af8b00\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "REPO = ['gtsueng/DDE-CrossWalks']  # format is username/repo\n",
    "#github_token: ${{ secrets.GITHUB_TOKEN }}\n",
    "github_info = json.load(open(os.path.join(parent_path,'github_credentials.json'),'rb'))\n",
    "PERSONAL_TOKEN = github_info['PERSONAL_TOKEN']\n",
    "\n",
    "# Change these parameters based on which issues you are actually searching, \n",
    "#see also here: https://developer.github.com/v3/issues/#parameters\n",
    "test = True\n",
    "check_repo(REPO, PERSONAL_TOKEN,parent_path,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0fbe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Pull basic metadata from spreadsheet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e75ab085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Update the repo to download new files from the list\n",
    "check_crosswalks_list(parent_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd59feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputurl = 'https://docs.google.com/spreadsheets/d/16kokDEZPDv_i4PFkbZGhrUHNhvRwv0M8Z6HNtZoqjbI/edit#gid=0'\n",
    "#inputurl = 'https://docs.google.com/spreadsheets/d/16kokDEZPDv_i4PFkbZGhrUHNhvRwv0M8Z6HNtZoqjbI/edit?usp=sharing'\n",
    "data_file = load_g_sheet_data(parent_path, inputurl)\n",
    "values = pd.read_excel(BytesIO(data_file),sheet_name='metainfo',header=0,index_col=None,engine=\"openpyxl\")\n",
    "fileid = values['value'].loc[values['property']=='identifier']\n",
    "version = values['value'].loc[values['property']=='dateModified']\n",
    "print(fileid.iloc[0])\n",
    "print(version.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5709558",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save xlsx template file given a publicly viewable google spreadsheet link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16065af",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosswalkstable = pd.read_csv(os.path.join(parent_path,'crosswalkslist.txt'),delimiter='\\t',header=0)\n",
    "print(crosswalkstable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1cc798",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd17599",
   "metadata": {},
   "outputs": [],
   "source": [
    "githuburl = crosswalkstable.iloc[0]['GitHubUrl']\n",
    "print(url)\n",
    "\n",
    "\n",
    "data_file = load_github_data(parent_path,githuburl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2218a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f67110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = 'test'\n",
    "url = 'https://docs.google.com/spreadsheets/d/16kokDEZPDv_i4PFkbZGhrUHNhvRwv0M8Z6HNtZoqjbI/edit#gid=0'\n",
    "\n",
    "download_spreadsheet(parent_path,url,identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a24669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert GitHub url\n",
    "\n",
    "'https://github.com/gtsueng/DDE-CrossWalks/raw/main/crosswalks/nde_biotools_computationaltool.xls'\n",
    "'https://github.com/gtsueng/DDE-CrossWalks/blob/mygene/crosswalks/nde_biotools_computationaltool.xls?raw=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761c5e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

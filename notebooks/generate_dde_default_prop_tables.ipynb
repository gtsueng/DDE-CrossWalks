{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b956f7a",
   "metadata": {},
   "source": [
    "## Generate default property tables based on schemas in the DDE\n",
    "\n",
    "These scripts were originally written to generate default property tables for the nde schema in the DDE\n",
    "\n",
    "It has been used to successfully export property tables for the nde:Dataset and nde:ComputationalTool schemas\n",
    "\n",
    "#### To do: \n",
    "Test the flexibility of the script by generating tables for:\n",
    "* outbreak:ComputationalTool (successful run)\n",
    "* outbreak:Dataset\n",
    "* niaid:Dataset\n",
    "* bioschemas:Protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18412adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4a4be85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gtsueng\\Anaconda3\\envs\\outbreak\\DDE-CrossWalks\n"
     ]
    }
   ],
   "source": [
    "nb_path = os.getcwd()\n",
    "parent_path = os.path.dirname(nb_path)\n",
    "metainfo = os.path.join(parent_path,'metainfo')\n",
    "print(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ec6b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse out basic information and clean up the resulting table\n",
    "def parse_marginality(validation_rules):\n",
    "    try:\n",
    "        required = validation_rules[\"required\"]\n",
    "        requiredDF = pd.DataFrame([{\"property\":x, \"marginality\":\"minimal or required\"} for x in required])\n",
    "    except:\n",
    "        requiredDF = []\n",
    "    try:\n",
    "        recommended = validation_rules[\"recommended\"]\n",
    "        recommendedDF = pd.DataFrame([{\"property\":x, \"marginality\":\"recommended\"} for x in recommended])\n",
    "    except:\n",
    "        recommendedDF = []\n",
    "    try:\n",
    "        optional = validation_rules[\"optional\"]\n",
    "        optionalDF = pd.DataFrame([{\"property\":x, \"marginality\":\"optional\"} for x in optional])\n",
    "    except:\n",
    "        optionalDF = []\n",
    "    marginality_rules = pd.concat((requiredDF,recommendedDF,optionalDF),ignore_index=True)\n",
    "    return marginality_rules\n",
    "\n",
    "def parse_cardinality(validation_rules):\n",
    "    property_dict = validation_rules[\"properties\"]\n",
    "    property_list = list(property_dict.keys())\n",
    "    try:\n",
    "        cardinality_list = [{\"property\":x,\"owl:cardinality\":property_dict[x][\"owl:cardinality\"]} for x in property_list]\n",
    "    except:\n",
    "        cardinality_list = []\n",
    "        for x in property_list:\n",
    "            if \"owl:cardinality\" in list(property_dict[x].keys()):\n",
    "                cardinality_list.append({\"property\":x,\"owl:cardinality\":property_dict[x][\"owl:cardinality\"]})\n",
    "            else:\n",
    "                cardinality_list.append({\"property\":x,\"owl:cardinality\":\"Unspecified\"})\n",
    "    cardinality_df = pd.DataFrame(cardinality_list)\n",
    "    return cardinality_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63293a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get property definitions\n",
    "## properties not defined in NDE should be checked in parent classes of NDE\n",
    "def get_schema(namespace,sdo=False):\n",
    "    if sdo == True:\n",
    "        schema_url = \"https://schema.org/version/latest/schemaorg-current-https.jsonld\"\n",
    "    else:\n",
    "        schema_base_url = \"https://discovery.biothings.io/api/registry/\"\n",
    "        schema_url = f\"{schema_base_url}{namespace}/\"\n",
    "    r = requests.get(schema_url)\n",
    "    result_schema = json.loads(r.text)    \n",
    "    return result_schema\n",
    "\n",
    "def get_defined_props(schema_results,sdo=False):\n",
    "    if sdo == True:\n",
    "        schema_hits = schema_results['@graph']\n",
    "    else:\n",
    "        schema_hits = schema_results['source']['@graph']\n",
    "    schema_props = []\n",
    "    for eachhit in schema_hits:\n",
    "        if eachhit[\"@type\"] == \"rdf:Property\":\n",
    "            schema_props.append(eachhit)        \n",
    "    return schema_props\n",
    "\n",
    "def convert_prop_df(schema_props,namespace):\n",
    "    tmpdf = pd.DataFrame(schema_props)\n",
    "    tmpdf.rename(columns={'rdfs:label':'property'},inplace=True)\n",
    "    tmpdf['domainIncludes'] = tmpdf.apply(lambda row: clean_ids(row['schema:domainIncludes']),axis=1)\n",
    "    tmpdf['rangeIncludes'] = tmpdf.apply(lambda row: clean_ids(row['schema:rangeIncludes']),axis=1)\n",
    "    cleandf = tmpdf[['property','domainIncludes',\n",
    "                     'rangeIncludes']].copy()\n",
    "    if namespace == \"schema\":\n",
    "        schema_base_url = \"https://schema.org/\"\n",
    "        cleandf[\"url\"] = [f\"{schema_base_url}{x}\" for x in cleandf['property']]\n",
    "    else:\n",
    "        schema_base_url = \"https://discovery.biothings.io/view/\"\n",
    "        cleandf[\"url\"] = [f\"{schema_base_url}{namespace}/{x}\" for x in cleandf['property']]\n",
    "    return cleandf\n",
    "\n",
    "\n",
    "def clean_ids(idlist):\n",
    "    if isinstance(idlist,float)==True:\n",
    "        cleanids = \"Unspecified\"\n",
    "    elif isinstance(idlist,list)==True:\n",
    "        idresults = [x['@id'] for x in idlist]\n",
    "        if len(idresults)<2:\n",
    "            cleanids = idresults[0]\n",
    "        else:\n",
    "            cleanids = idresults\n",
    "    elif isinstance(idlist,dict)==True:\n",
    "        cleanids = idlist['@id']\n",
    "    else:\n",
    "        print(idlist)\n",
    "    return cleanids\n",
    "\n",
    "def generate_schema_propdf():\n",
    "    sdo = True\n",
    "    namespace = \"schema\"\n",
    "    base_url = \"https://schema.org\"\n",
    "    sdo_schema = get_schema(namespace,sdo)\n",
    "    sdo_props = get_defined_props(sdo_schema,sdo)\n",
    "    schema_prop_df = convert_prop_df(sdo_props,namespace)\n",
    "    schema_prop_df['property'] = schema_prop_df['property'].astype(str)\n",
    "    return schema_prop_df\n",
    "\n",
    "#### Searching for properties in parent classes \n",
    "##Look into the @context to find used classes/namespaces  \n",
    "def generate_namespace_list(namespace,sdo=False):\n",
    "    foundations = [\"rdf\",\"rdfs\",\"owl\"]\n",
    "    if sdo==True:\n",
    "        result_schema = get_schema(namespace)\n",
    "        context_dict = {}\n",
    "    else:\n",
    "        result_schema = get_schema(namespace,sdo)\n",
    "        context_dict = result_schema['source']['@context']\n",
    "        for eachfoundation in foundations:\n",
    "            try:\n",
    "                context_dict.pop(eachfoundation)\n",
    "            except:\n",
    "                continue\n",
    "    return context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eead5545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_schema_classes(namespace,raw=False):\n",
    "    result_schema = get_schema(namespace,sdo=False)\n",
    "    if raw == False:\n",
    "        schema_class_list = result_schema['hits']\n",
    "    else:\n",
    "        schema_hits = result_schema['source']['@graph']\n",
    "        schema_class_list = []\n",
    "        for eachhit in schema_hits:\n",
    "            if eachhit[\"@type\"] == \"rdfs:Class\":\n",
    "                schema_class_list.append(eachhit)\n",
    "    return schema_class_list\n",
    "\n",
    "\n",
    "def fetch_specific_class(namespace,schematype,raw=False):\n",
    "    if raw == False:\n",
    "        schema_class_list = fetch_schema_classes(namespace)\n",
    "    else:\n",
    "        schema_class_list = fetch_schema_classes(namespace,raw)\n",
    "    for eachhit in schema_class_list:\n",
    "        try:\n",
    "            if eachhit[\"rdfs:label\"] == schematype:\n",
    "                return eachhit\n",
    "        except:\n",
    "            if eachhit[\"label\"] == schematype:\n",
    "                return eachhit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd3695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_class_info(namespace):\n",
    "    schema_class_list = fetch_schema_classes(namespace,raw=False)\n",
    "    schema_parents_dict = {}\n",
    "    for eachclass in schema_class_list:\n",
    "        schema_parents_dict[eachclass[\"name\"]] = eachclass[\"parent_classes\"]\n",
    "    return schema_parents_dict\n",
    "\n",
    "## parses a list encoded as a string\n",
    "def parse_fake_list(fake_list):\n",
    "    if isinstance(fake_list,list): ## the list is actually a list\n",
    "        if len(fake_list) == 1: ## however, the list has only string entry which needs to be parsed\n",
    "            real_list = fake_list[0].split(',')\n",
    "        else:\n",
    "            real_list = fake_list\n",
    "    elif isinstance(fake_list,text): ## the list is a string encoded list\n",
    "        real_list = fake_list.strip('[').strip(']').split(',')\n",
    "    else:\n",
    "        print(fake_list.type)\n",
    "    return real_list\n",
    "\n",
    "def get_parent_order(namespace,schema_class):\n",
    "    schema_parents_dict = get_parent_class_info(namespace)\n",
    "    real_list = parse_fake_list(schema_parents_dict[schema_class])\n",
    "    temp_list = [x.split(':')[0] for x in real_list]\n",
    "    temp_list = [x.strip() for x in temp_list]\n",
    "    schema_order = list(OrderedDict.fromkeys(temp_list))\n",
    "    ## Add the namespace (which will always be last in order)\n",
    "    schema_order.append(namespace)\n",
    "    return schema_order\n",
    "\n",
    "def reorder_list(schema_order):\n",
    "    new_order = []\n",
    "    i = -1\n",
    "    while abs(i)<=len(schema_order):\n",
    "        namespace = schema_order[i]\n",
    "        new_order.append(namespace)\n",
    "        i=i-1 \n",
    "    return new_order\n",
    "\n",
    "## Get marginality and cardinality data for all the properties\n",
    "def get_margin_cardin(namespace,schema_class):\n",
    "    schematype = schema_class.split(':')[1]\n",
    "    class_schema = fetch_specific_class(namespace,schematype,raw=True)\n",
    "    validation_rules = class_schema[\"$validation\"]\n",
    "    marginalityDF = parse_marginality(validation_rules)\n",
    "    cardinalityDF = parse_cardinality(validation_rules)\n",
    "    baseDF = marginalityDF.merge(cardinalityDF,on=\"property\",how=\"outer\")\n",
    "    return baseDF\n",
    "\n",
    "def generate_prop_df(namespace, schema_class):\n",
    "    sdo_prop_df = generate_schema_propdf()\n",
    "    cleanDF = pd.DataFrame(columns = ['property','owl:cardinality','marginality',\n",
    "                                      'domainIncludes','rangeIncludes','url'])\n",
    "    ignore_props = []\n",
    "    baseDF = get_margin_cardin(namespace,schema_class)\n",
    "    schema_order = get_parent_order(namespace,schema_class)\n",
    "    priority_order = reorder_list(schema_order)\n",
    "    for eachnamespace in priority_order:\n",
    "        if eachnamespace != 'schema':\n",
    "            result_schema = get_schema(eachnamespace)\n",
    "            schema_props = get_defined_props(result_schema)\n",
    "            defined_props = convert_prop_df(schema_props,eachnamespace)\n",
    "            lessDF = baseDF.loc[~baseDF['property'].isin(ignore_props)]\n",
    "            tmpdf = lessDF.merge(defined_props,on=\"property\",how=\"inner\")\n",
    "            ignore_props.extend(tmpdf['property'].unique().tolist())\n",
    "            cleanDF = pd.concat((cleanDF,tmpdf),ignore_index=True)\n",
    "        else:\n",
    "            ## deal with schema.org props\n",
    "            lessDF = baseDF.loc[~baseDF['property'].isin(ignore_props)]\n",
    "            tmpdf = lessDF.merge(sdo_prop_df,on=\"property\",how=\"inner\")\n",
    "            cleanDF = pd.concat((cleanDF,tmpdf),ignore_index=True)\n",
    "    return cleanDF\n",
    "\n",
    "def clean_up_schema(cleanDF, schema_class):\n",
    "    cleanDF.rename(columns={\"property\":f\"sameAs.{schema_class}\",\n",
    "               \"marginality\":\"sameAs.marginality\",\n",
    "               \"owl:cardinality\":\"sameAs.owl:cardinality\",\n",
    "               \"domainIncludes\":\"sameAs.domainIncludes\",\n",
    "               \"rangeIncludes\":\"sameAs.rangeIncludes\",\n",
    "               \"url\":\"sameAs.url\"},inplace=True)\n",
    "    cleanclassDF = cleanDF[[f\"sameAs.{schema_class}\",\"sameAs.owl:cardinality\",\"sameAs.marginality\",\n",
    "                           \"sameAs.domainIncludes\",\"sameAs.rangeIncludes\",\"sameAs.url\"]].copy()\n",
    "    return cleanclassDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8bfbf53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sameAs.nde:Dataset sameAs.owl:cardinality   sameAs.marginality  \\\n",
      "0                   date                    one  minimal or required   \n",
      "1  includedInDataCatalog                    one  minimal or required   \n",
      "\n",
      "                  sameAs.domainIncludes sameAs.rangeIncludes  \\\n",
      "0  [nde:Dataset, nde:ComputationalTool]          schema:Date   \n",
      "1                 nde:ComputationalTool   schema:DataCatalog   \n",
      "\n",
      "                                          sameAs.url  \n",
      "0       https://discovery.biothings.io/view/nde/date  \n",
      "1  https://discovery.biothings.io/view/nde/includ...  \n"
     ]
    }
   ],
   "source": [
    "namespace = \"nde\"\n",
    "schema_class = 'nde:Dataset'\n",
    "ndeDF = generate_prop_df(namespace, schema_class)\n",
    "cleanndeDF = clean_up_schema(ndeDF, schema_class)\n",
    "print(cleanndeDF.head(n=2))\n",
    "cleanndeDF.to_csv(os.path.join(metainfo,'nde','nde_dataset_props.tsv'),sep='\\t',header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5cd13b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sameAs.nde:ComputationalTool sameAs.owl:cardinality   sameAs.marginality  \\\n",
      "0                         date                    one  minimal or required   \n",
      "1        includedInDataCatalog            Unspecified  minimal or required   \n",
      "\n",
      "                  sameAs.domainIncludes sameAs.rangeIncludes  \\\n",
      "0  [nde:Dataset, nde:ComputationalTool]          schema:Date   \n",
      "1                 nde:ComputationalTool   schema:DataCatalog   \n",
      "\n",
      "                                          sameAs.url  \n",
      "0       https://discovery.biothings.io/view/nde/date  \n",
      "1  https://discovery.biothings.io/view/nde/includ...  \n"
     ]
    }
   ],
   "source": [
    "namespace = \"nde\"\n",
    "schema_class = 'nde:ComputationalTool'\n",
    "ndectDF = generate_prop_df(namespace, schema_class)\n",
    "cleanndectDF = clean_up_schema(ndectDF, schema_class)\n",
    "print(cleanndectDF.head(n=2))\n",
    "cleanndectDF.to_csv(os.path.join(metainfo,'nde','nde_comptools_props.tsv'),sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f857fcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sameAs.outbreak:ComputationalTool sameAs.owl:cardinality  \\\n",
      "0                            author            Unspecified   \n",
      "1                           funding            Unspecified   \n",
      "\n",
      "    sameAs.marginality                              sameAs.domainIncludes  \\\n",
      "0  minimal or required  [outbreak:Analysis, outbreak:Dataset, outbreak...   \n",
      "1  minimal or required  [outbreak:Dataset, outbreak:Publication, outbr...   \n",
      "\n",
      "                       sameAs.rangeIncludes  \\\n",
      "0  [outbreak:Person, outbreak:Organization]   \n",
      "1                      schema:MonetaryGrant   \n",
      "\n",
      "                                          sameAs.url  \n",
      "0  https://discovery.biothings.io/view/outbreak/a...  \n",
      "1  https://discovery.biothings.io/view/outbreak/f...  \n"
     ]
    }
   ],
   "source": [
    "namespace = \"outbreak\"\n",
    "schema_class = 'outbreak:ComputationalTool'\n",
    "ndectDF = generate_prop_df(namespace, schema_class)\n",
    "cleanndectDF = clean_up_schema(ndectDF, schema_class)\n",
    "print(cleanndectDF.head(n=2))\n",
    "cleanndectDF.to_csv(os.path.join(metainfo,'nde','outbreak_comptools_props.tsv'),sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9085c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8ed434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ea4ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3602ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f381a4a2",
   "metadata": {},
   "source": [
    "## Deprecated functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ab352",
   "metadata": {},
   "outputs": [],
   "source": [
    "## translate general expected types\n",
    "## This has yet to be completed due to the levels of nesting involved (dictionaries, to lists, to dictionaries)\n",
    "## Note, it doesn't make sense to try this approach, instead we can pull this info from property definitions\n",
    "def transform_prop_types(proptypelist,prop_validation):\n",
    "    if prop_validation[\"type\"] == \"string\":\n",
    "        try:\n",
    "            if prop_validation[\"format\"] == \"date\":\n",
    "                proptypelist.append({\"schema:Date\"})\n",
    "            if prop_validation[\"format\"] == \"uri\":\n",
    "                proptypelist.append({\"schema:URL\"})\n",
    "        except:\n",
    "            proptypelist.append({\"schema:Text\"})\n",
    "    if prop_validation[\"type\"] == \"boolean\":\n",
    "        proptypelist.append({\"schema:Boolean\"})\n",
    "    if prop_validation[\"type\"] == \"integer\":\n",
    "        proptypelist.append({\"schema:Integer\"})\n",
    "    if prop_validation[\"type\"] == \"number\":\n",
    "        proptypelist.append({\"schema:Number\"})    \n",
    "    return proptypelist\n",
    "\n",
    "\n",
    "def generate_def_dict(class_definitions):\n",
    "    def_dict = {}\n",
    "    for k,v in class_definitions.items():\n",
    "        try:\n",
    "            def_dict[k] = {f\"schema:{v['@type']}\"}\n",
    "        except:\n",
    "            def_dict[k] = \"JSON schema object\"\n",
    "    return def_dict\n",
    "    \n",
    "def lookup_reference(proptypelist,reference_value,def_dict):\n",
    "    reference_prop = reference_value.replace(\"#/definitions/\",\"\")\n",
    "    proptypelist.append(def_dict[reference_prop])\n",
    "    return proptypelist\n",
    "\n",
    "def get_ref_value(prop_dict):\n",
    "    if \"$ref\" in list(prop_dict.keys()):\n",
    "        reference_value = prop_dict[\"$ref\"]\n",
    "    return reference_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

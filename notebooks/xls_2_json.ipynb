{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a738804f",
   "metadata": {},
   "source": [
    "## XLS To Xwalk converter\n",
    "\n",
    "This script generates a crosswalks:MetadataCrossWalk schema-compliant JSONLD file.\n",
    "\n",
    "1. Assumes mapping happens between only two schemas (ie - only one mapping)\n",
    "2. Inverted mappings can be auto-generated, but certain properties are directional and will not be included in the inverted mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50c438ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_excel\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b677810",
   "metadata": {},
   "source": [
    "#### Excel template sheet info\n",
    "\n",
    "* **metaInfo**: Information about the crosswalk itself. For example, 'author' refers to the authors of the crosswalk, not the authors of the schemas evaluated/mapped in the crosswalk.\n",
    "* **authorInfo**: The authors of the crosswalk. This sheet is used to create an array of Person or Organization objects\n",
    "* **fundingInfo**: Funding information for the development of the crosswalk.\n",
    "* **schemaObjects**: Information about the two schema being compared/mapped.\n",
    " * **schemaOriginObject**: The subject schema\n",
    " * **schemaTargetObject**: The object schema\n",
    " * **schemaUsageObject**: Schemas or crosswalks that uses this metadata crosswalk or mapping\n",
    "* **nestedProps**: Information for other nested objects which are the expected values of properties of the MetadataCrosswalk\n",
    "* **propertyList**: The sheet actually showing the mapping of the properties from one schema to the next. Column names should reference the schema, and additional information on \n",
    "\n",
    "For individual properties with multiple ranges or domains included, each range or domainIncluded should be delimited by a comma only.\n",
    "\n",
    "Because different schemas may nest properties differently, all properties should be listed and mapped based on the nesting within the class to be mapped. Nested properties that can be mapped should be denoted using dot notation: eg-parent_object.property. Properties belonging to classes that are referenced but not part of the parent class should be included based on the reference property. For example, the property 'doi' in the NIAID schema belongs to the ScholarlyArticle class, not the Dataset class; however, it will be referenced in the Dataset class using the 'citation' property. Hence, it should be included/mapped as 'citation.doi'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b4c66fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_list(contextdf):\n",
    "    context_dict = {}\n",
    "    for i in range(len(contextdf)):\n",
    "        contextdf.fillna('null',inplace=True)\n",
    "        tmpnamespace = contextdf.iloc[i]['namespace']\n",
    "        tmpuri = contextdf.iloc[i]['@context']\n",
    "        context_dict[str(tmpnamespace)]=str(tmpuri)\n",
    "    clean_context = dict((k, v) for k, v in context_dict.items() if v!='null')\n",
    "    if \"schema\" not in list(clean_context.keys()):\n",
    "        clean_context[\"schema\"] = \"https://schema.org/\"\n",
    "    if \"owl\" not in list(clean_context.keys()):\n",
    "        clean_context[\"owl\"] = \"http://www.w3.org/2002/07/owl/\"\n",
    "    if \"rdf\" not in list(clean_context.keys()):\n",
    "        clean_context[\"rdf\"] = \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n",
    "    if \"rdfs\" not in list(clean_context.keys()):\n",
    "        clean_context[\"rdfs\"] = \"http://www.w3.org/2000/01/rdf-schema#\"\n",
    "    return clean_context\n",
    "\n",
    "def clean_citations(schemaObject):\n",
    "    citationdf = schemaObject[['citation.@type','citation.name','citation.url']].copy()\n",
    "    citationdf.rename(columns={'citation.@type':'@type','citation.name':'name','citation.url':'url'},inplace=True)\n",
    "    citejson = citationdf.to_dict(orient='records')\n",
    "    schemaObject['citation'] = [x for x in citejson]\n",
    "    schemaObject.drop(columns = ['citation.@type','citation.name','citation.url'], axis=1,inplace=True)\n",
    "    return schemaObject\n",
    "\n",
    "def load_authors(data_file):\n",
    "    try:\n",
    "        author_info = read_excel(data_file,sheet_name='authorInfo',header=0,index_col=None)\n",
    "    except:\n",
    "        author_info = read_excel(data_file,sheet_name='authorInfo',header=0,index_col=None,engine=\"openpyxl\")        \n",
    "    author_object = author_info.to_dict(orient=\"records\")\n",
    "    return author_object\n",
    "\n",
    "def load_funding(data_file):\n",
    "    try:\n",
    "        funding_info = read_excel(data_file,sheet_name='fundingInfo',header=0,index_col=None)\n",
    "    except:\n",
    "        funding_info = read_excel(data_file,sheet_name='fundingInfo',header=0,index_col=None,engine=\"openpyxl\")        \n",
    "    if len(funding_info)>0:\n",
    "        funder_info = funding_info[['funder.@type','funder.name']].copy()\n",
    "        funder_info.rename(columns={'funder.@type':'@type','funder.name':'name'}, inplace=True)\n",
    "        funder_dict_list = funder_info.to_dict(orient=\"records\")\n",
    "        funding = funding_info[['@type','identifier']].copy()\n",
    "        funding['funder'] = [x for x in funder_dict_list]\n",
    "        fundingdict = funding.to_dict(orient=\"records\")\n",
    "    else:\n",
    "        fundingdict = {}\n",
    "    return fundingdict\n",
    "\n",
    "def load_schema_objects(data_file):\n",
    "    try:\n",
    "        schemaObjects = read_excel(data_file,sheet_name='schemaObjects',header=0,index_col=None)\n",
    "    except:\n",
    "        schemaObjects = read_excel(data_file,sheet_name='schemaObjects',header=0,index_col=None,engine=\"openpyxl\")        \n",
    "    schemaObjects['version'] = schemaObjects.apply(lambda row: clean_up_dates(row['version']), axis=1)\n",
    "    schemaContext = schemaObjects[['namespace','@context']].copy()\n",
    "    context_dict = generate_context_list(schemaContext)\n",
    "    schemaObjects = clean_citations(schemaObjects)\n",
    "    schemaOriginObjects = schemaObjects.loc[schemaObjects['objectType']=='schemaOriginObject'].copy()\n",
    "    schemaTargetObjects = schemaObjects.loc[schemaObjects['objectType']=='schemaTargetObject'].copy()\n",
    "    schemaOriginObjects.drop(['namespace','@context','objectType'],axis=1,inplace=True)\n",
    "    schemaTargetObjects.drop(['namespace','@context','objectType'],axis=1,inplace=True)\n",
    "    schemaOriginList = schemaOriginObjects.to_dict(orient=\"records\")\n",
    "    schemaTargetList = schemaTargetObjects.to_dict(orient=\"records\")\n",
    "    try:\n",
    "        schemaUsageObjects = schemaObjects.loc[schemaObjects['objectType']=='schemaUsageObject'].copy()    \n",
    "        schemaUsageObjects.drop(['namespace','@context','objectType'],axis=1,inplace=True)\n",
    "        schemaUsageList = schemaUsageObjects.to_dict(orient=\"records\")\n",
    "    except:\n",
    "        schemaUsageList = None\n",
    "    idlist = schemaObjects['identifier'].unique().tolist()\n",
    "    return schemaOriginList, schemaTargetList, schemaUsageList, context_dict, idlist\n",
    "\n",
    "def merge_schema_objects(schemaOriginList,schemaTargetList):\n",
    "    schemalist = []\n",
    "    for x in schemaOriginList:\n",
    "        schemalist.append(x)\n",
    "    for y in schemaTargetList:\n",
    "        schemalist.append(y)\n",
    "    return schemalist\n",
    "\n",
    "def load_schema_usage_objects(schemaUsageList):\n",
    "    schemalist = []\n",
    "    for z in schemaUsageList:\n",
    "        schemalist.append(z)\n",
    "    return schemalist\n",
    "    \n",
    "def clean_up_dates(propvalue):\n",
    "    if type(propvalue)==str:\n",
    "        tmppropvalue = propvalue.strip('\"')\n",
    "        cleanpropvalue = tmppropvalue.strip(\"'\")\n",
    "    elif isinstance(propvalue,datetime):\n",
    "        cleanpropvalue = datetime.strftime(propvalue,\"%Y-%m-%d\")\n",
    "    else:\n",
    "        cleanpropvalue = propvalue\n",
    "    return cleanpropvalue\n",
    "\n",
    "def parse_nestedProps(data_file):\n",
    "    try:\n",
    "        nestedProps = read_excel(data_file,sheet_name='nestedProps',header=0,index_col=None)\n",
    "    except:\n",
    "        nestedProps = read_excel(data_file,sheet_name='nestedProps',header=0,index_col=None,engine=\"openpyxl\")        \n",
    "    nestedProps.fillna(\"null\",inplace=True)\n",
    "    proplist = nestedProps['property'].unique().tolist()\n",
    "    propdict = {}\n",
    "    for eachprop in proplist:\n",
    "        tmpdf = nestedProps.loc[nestedProps['property']==eachprop].copy()\n",
    "        tmpdf.drop('property',axis=1,inplace=True)\n",
    "        tmpdict = tmpdf.to_dict(orient=\"records\")\n",
    "        cleandict = []\n",
    "        for eachdict in tmpdict:\n",
    "            cleandict.append(dict((k, v) for k, v in eachdict.items() if v!=\"null\"))\n",
    "        propdict[eachprop] = cleandict\n",
    "    return propdict\n",
    "\n",
    "#### value string formatting functions\n",
    "def format_iri_as_id(example_iri):\n",
    "    iri_list = example_iri.split(',')\n",
    "    tmplist = []\n",
    "    for each_iri in iri_list:\n",
    "        iri_dict = {\"@id\":each_iri}\n",
    "        tmplist.append(iri_dict)\n",
    "    return tmplist   \n",
    "\n",
    "def get_last_element(nestedname):\n",
    "    namelist = nestedname.split('.')\n",
    "    if len(namelist)>1:\n",
    "        last_element = namelist[-1]\n",
    "    if len(namelist)==1:\n",
    "        last_element = namelist[0]\n",
    "    if len(namelist)==0:\n",
    "        last_element = nestedname\n",
    "    return last_element\n",
    "\n",
    "#### property functions\n",
    "def add_type(propertydf):\n",
    "    propertydf['@type'] = \"schema:Property\"\n",
    "    return propertydf\n",
    "\n",
    "def cleanup_domain_range(propertydf):\n",
    "    try:\n",
    "        propertydf['rangeIncludes'] = propertydf.apply(lambda row: format_iri_as_id(row['rangeIncludes']), axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        propertydf['domainIncludes'] = propertydf.apply(lambda row: format_iri_as_id(row['domainIncludes']), axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    return propertydf\n",
    "\n",
    "def idlist_to_renamedf(idlist):\n",
    "    renamedf = {}\n",
    "    for eachid in idlist:\n",
    "        renamedf[eachid] = 'property'\n",
    "    return renamedf\n",
    "\n",
    "def generate_isPartOf_info(propertydf,idlist):\n",
    "    partid = [col for col in propertydf.columns if col in idlist]\n",
    "    tmpdict = {'@id': partid[0]}\n",
    "    return tmpdict\n",
    "\n",
    "def clean_up_source_id(propertydf,idlist):\n",
    "    partdict = generate_isPartOf_info(propertydf,idlist)\n",
    "    renamedf = idlist_to_renamedf(idlist)\n",
    "    propertydf.rename(columns=renamedf,inplace=True)\n",
    "    propertydf['isPartOf'] = [partdict for x in propertydf['property']]\n",
    "    return propertydf\n",
    "\n",
    "def clean_up_prop_names(propertydf):\n",
    "    propertydf.rename(columns = {'property':'nestedName'},inplace=True)\n",
    "    propertydf['name'] = propertydf.apply(lambda row: get_last_element(row['nestedName']), axis=1)\n",
    "    return propertydf\n",
    "\n",
    "def clean_up_props(propertydf,idlist):\n",
    "    propertydf = clean_up_source_id(propertydf,idlist)\n",
    "    propertydf = clean_up_prop_names(propertydf)\n",
    "    propertydf = cleanup_domain_range(propertydf)\n",
    "    return propertydf\n",
    "\n",
    "    \n",
    "def generate_prop_included(data_file,idlist):\n",
    "    try:\n",
    "        proplist = read_excel(data_file,sheet_name='propertyList',header=0,index_col=None)\n",
    "    except:\n",
    "        proplist = read_excel(data_file,sheet_name='propertyList',header=0,index_col=None,engine=\"openpyxl\")\n",
    "    proplist.dropna(axis=1, how='all', inplace=True)\n",
    "    same_cols = [col for col in proplist.columns if 'sameAs' in col]\n",
    "    source_cols = [col for col in proplist.columns if 'sameAs' not in col]\n",
    "    sourcedf = proplist[source_cols].copy()\n",
    "    sourcedf = clean_up_props(sourcedf,idlist)\n",
    "    samedf = proplist[same_cols].copy()\n",
    "    samedf.rename(columns=lambda s: s.replace(\"sameAs.\", \"\"), inplace=True)\n",
    "    samedf = clean_up_props(samedf,idlist)\n",
    "    samedict = samedf.to_dict(orient=\"records\")\n",
    "    sourcedf['sameAs'] = samedict\n",
    "    propdictlist = sourcedf.to_dict(orient=\"records\")\n",
    "    return propdictlist\n",
    "    \n",
    "\n",
    "def convert_xls_xwalk(data_file):\n",
    "    author_object = load_authors(data_file)\n",
    "    funding_object = load_funding(data_file)\n",
    "    schemaOriginList, schemaTargetList, schemaUsageList, context_dict, idlist = load_schema_objects(data_file)\n",
    "    propdict = parse_nestedProps(data_file)\n",
    "    includedprops = generate_prop_included(data_file,idlist)\n",
    "    try:\n",
    "        xwalkmeta = read_excel(data_file,sheet_name='metaInfo',header=0,index_col=0)\n",
    "    except:\n",
    "        xwalkmeta = read_excel(data_file,sheet_name='metaInfo',header=0,index_col=0,engine=\"openpyxl\")        \n",
    "    xwalkmeta.dropna(inplace=True)\n",
    "    xwalkdict = xwalkmeta.to_dict()\n",
    "    xwalkclean = OrderedDict(xwalkdict['value'])\n",
    "    xwalkclean['@context'] = context_dict\n",
    "    xwalkclean['@type'] = 'crosswalks:MetadataCrosswalk'\n",
    "    xwalkclean['author'] = author_object\n",
    "    if len(funding_object)>0:\n",
    "        xwalkclean['funding'] = funding_object\n",
    "    xwalkclean['hasPart'] = merge_schema_objects(schemaOriginList,schemaTargetList)\n",
    "    xwalkclean['datePublished'] = clean_up_dates(xwalkclean['datePublished'])\n",
    "    xwalkclean['dateModified'] = clean_up_dates(xwalkclean['dateModified'])\n",
    "    try:\n",
    "        xwalkclean['isBasedOn'] = propdict['isBasedOn']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        xwalkclean['isBasisFor'] = propdict['isBasisFor']\n",
    "    except:\n",
    "        pass\n",
    "    xwalkclean['includesProperty'] = includedprops\n",
    "    if schemaUsageList != None:\n",
    "        xwalkclean['isPartOf'] = load_schema_usage_objects(schemaUsageList)\n",
    "    return xwalkclean\n",
    "\n",
    "\n",
    "def invert_mappings(property_list):\n",
    "    inverted_prop_list = []\n",
    "    for eachprop in property_list:\n",
    "        newprop = eachprop.pop('sameAs')\n",
    "        newprop['sameAs'] = eachprop\n",
    "        inverted_prop_list.append(newprop)\n",
    "    return inverted_prop_list\n",
    "\n",
    "\n",
    "def generate_inverted_crosswalk(xwalkclean):\n",
    "    property_list = xwalkclean['includesProperty']\n",
    "    inverted_props = invert_mappings(property_list)\n",
    "    original_id = xwalkclean['identifier']\n",
    "    new_id = 'inverted_'+original_id\n",
    "    invertedxwalk = deepcopy(xwalkclean)\n",
    "    invertedxwalk['identifier'] = new_id\n",
    "    invertedxwalk['includesProperty']=inverted_props\n",
    "    return(invertedxwalk)\n",
    "\n",
    "\n",
    "def convert_crosswalks(script_path):\n",
    "    data_path = os.path.join(script_path,'crosswalks')\n",
    "    export_path = os.path.join(script_path,'jsoncrosswalks')\n",
    "    data_files = os.listdir(data_path)\n",
    "    for filename in data_files:\n",
    "        data_file = os.path.join(data_path,filename)\n",
    "        clean_filename = filename.replace('.xlsx','.xls')\n",
    "        export_file = os.path.join(script_path,'jsoncrosswalks',clean_filename.replace('.xls','.json'))\n",
    "        inverted_export_file = os.path.join(script_path,'jsoncrosswalks',clean_filename.replace('.xls','_inverted.json'))\n",
    "        try:\n",
    "            xwalkjson = convert_xls_xwalk(data_file)\n",
    "            with open(export_file,'w') as outfile:\n",
    "                jsonfile = json.dumps(xwalkjson, indent=2)\n",
    "                outfile.write(jsonfile)\n",
    "            invertedxwalk = generate_inverted_crosswalk(xwalkjson)\n",
    "            with open(inverted_export_file,'w') as outfile:\n",
    "                jsonfile = json.dumps(invertedxwalk, indent=2)\n",
    "                outfile.write(jsonfile)\n",
    "        except:\n",
    "            print(\"failed to convert: \",filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44dcd87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Function to convert a single crosswalk\n",
    "def convert_a_crosswalk(script_path,filename):\n",
    "    data_file = os.path.join(script_path,'crosswalks',filename)\n",
    "    clean_filename = filename.replace('.xlsx','.xls')\n",
    "    export_file = os.path.join(script_path,'jsoncrosswalks',clean_filename.replace('.xls','.json'))\n",
    "    inverted_export_file = os.path.join(script_path,'jsoncrosswalks',clean_filename.replace('.xls','_inverted.json'))\n",
    "    try:\n",
    "        xwalkjson = convert_xls_xwalk(data_file)\n",
    "        with open(export_file,'w') as outfile:\n",
    "            jsonfile = json.dumps(xwalkjson, indent=2)\n",
    "            outfile.write(jsonfile)\n",
    "        invertedxwalk = generate_inverted_crosswalk(xwalkjson)\n",
    "        with open(inverted_export_file,'w') as outfile:\n",
    "            jsonfile = json.dumps(invertedxwalk, indent=2)\n",
    "            outfile.write(jsonfile)\n",
    "    except:\n",
    "        print(\"failed to convert: \",filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a21336d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to convert:  nde_bioconducter_computationaltool.xls\n",
      "failed to convert:  nde_biotools_computationaltool.xls\n",
      "failed to convert:  nde_clinepidb_dataset.xls\n",
      "failed to convert:  nde_outbreak.xls\n",
      "failed to convert:  nde_outbreak_dataset.xls\n",
      "failed to convert:  nde_vivli_dataset.xls\n",
      "failed to convert:  nde_vuepathdb_dataset.xls\n",
      "failed to convert:  niaid_nde_dataset.xls\n",
      "failed to convert:  schema_google_dataset.xls\n"
     ]
    }
   ],
   "source": [
    "## Main\n",
    "\n",
    "script_path = ''\n",
    "data_path = os.path.join(script_path,'crosswalks')\n",
    "export_path = os.path.join(script_path,'jsoncrosswalks')\n",
    "data_files = os.listdir(data_path)\n",
    "for filename in data_files:\n",
    "    data_file = os.path.join(data_path,filename)\n",
    "    export_file = os.path.join(export_path,filename.replace('xls','json').replace('xlsx','json'))\n",
    "    inverted_export_file = os.path.join(export_path,filename.replace('.xls','_inverted.json').replace('.xlsx','_inverted.json'))\n",
    "try:\n",
    "    xwalkjson = convert_xls_xwalk(data_file)\n",
    "    with open(export_file,'w') as outfile:\n",
    "        jsonfile = json.dumps(xwalkjson, indent=2)\n",
    "        outfile.write(jsonfile)\n",
    "    invertedxwalk = generate_inverted_crosswalk(xwalkjson)\n",
    "    with open(inverted_export_file,'w') as outfile:\n",
    "        jsonfile = json.dumps(invertedxwalk, indent=2)\n",
    "        outfile.write(jsonfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb3d95b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#script_path = ''\n",
    "nb_path = os.getcwd()\n",
    "script_path = os.path.dirname(nb_path)\n",
    "data_path = os.path.join(script_path,'crosswalks')\n",
    "export_path = os.path.join(script_path,'jsoncrosswalks')\n",
    "filename = 'acd_niaid_xref_nde_dataset.xlsx'\n",
    "\n",
    "data_file = os.path.join(script_path,'crosswalks',filename)\n",
    "clean_filename = filename.replace('.xlsx','.xls')\n",
    "export_file = os.path.join(script_path,'jsoncrosswalks',clean_filename.replace('xls','json'))\n",
    "inverted_export_file = os.path.join(script_path,'jsoncrosswalks',clean_filename.replace('.xls','_inverted.json'))\n",
    "\n",
    "xwalkjson = convert_xls_xwalk(data_file)\n",
    "\n",
    "with open(export_file,'w') as outfile:\n",
    "    jsonfile = json.dumps(xwalkjson, indent=2)\n",
    "    outfile.write(jsonfile)\n",
    "invertedxwalk = generate_inverted_crosswalk(xwalkjson)\n",
    "with open(inverted_export_file,'w') as outfile:\n",
    "    jsonfile = json.dumps(invertedxwalk, indent=2)\n",
    "    outfile.write(jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62f5de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_export_file = os.path.join(export_path,filename.replace('.xls','_inverted.json').replace('.xlsx','_inverted.json'))\n",
    "invertedxwalk = generate_inverted_crosswalk(xwalkjson)\n",
    "#with open(inverted_export_file,'w') as outfile:\n",
    "#    jsonfile = json.dumps(invertedxwalk, indent=2)\n",
    "#    outfile.write(jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e4594c",
   "metadata": {},
   "source": [
    "### Validate the json output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea2e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonschema\n",
    "from jsonschema import validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53945366",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the json schema\n",
    "\n",
    "script_path = ''\n",
    "data_path = os.path.join(script_path,'crosswalks')\n",
    "export_path = os.path.join(script_path,'jsoncrosswalks')\n",
    "#data_file = os.path.join(data_path,'vuepathdb.xls')\n",
    "#export_file = os.path.join(export_path,'vuepathdb.json')\n",
    "schema_path = os.path.join(script_path,'schema')\n",
    "schema_file = os.path.join(schema_path,'MetadataCrossWalk.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(export_file,'r') as inputfile:\n",
    "    jsondata = json.load(inputfile)\n",
    "\n",
    "with open(schema_file,'r') as schemainput:\n",
    "    testschema = json.load(schemainput)\n",
    "\n",
    "validate(testschema, schema=jsondata)\n",
    "validate(testschema['@graph'][0]['$validation'], schema=jsondata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdebcac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "daa2871f",
   "metadata": {},
   "source": [
    "### Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b390c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main\n",
    "nb_path = os.getcwd()\n",
    "script_path = os.path.dirname(nb_path)\n",
    "#script_path = ''\n",
    "data_path = os.path.join(script_path,'crosswalks')\n",
    "export_path = os.path.join(script_path,'jsoncrosswalks')\n",
    "#data_file = os.path.join(data_path,'vuepathdb.xls')\n",
    "#export_file = os.path.join(export_path,'vuepathdb.json')\n",
    "data_files = os.listdir(data_path)\n",
    "\n",
    "for filename in data_files:\n",
    "    data_file = os.path.join(data_path,filename)\n",
    "    export_file = os.path.join(export_path,filename.replace('xlsx','json').replace('xls','json'))\n",
    "    inverted_export_file = os.path.join(export_path,filename.replace('.xlsx','_inverted.json').replace('.xls','_inverted.json'))\n",
    "    try:\n",
    "        xwalkjson = convert_xls_xwalk(data_file)\n",
    "        with open(export_file,'w') as outfile:\n",
    "            jsonfile = json.dumps(xwalkjson, indent=2)\n",
    "            outfile.write(jsonfile)\n",
    "        invertedxwalk = generate_inverted_crosswalk(xwalkjson)\n",
    "        with open(inverted_export_file,'w') as outfile:\n",
    "            jsonfile = json.dumps(invertedxwalk, indent=2)\n",
    "            outfile.write(jsonfile)\n",
    "    except:\n",
    "        print(\"failed to convert: \",filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e09ca664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'@type': 'CreativeWork', 'identifier': 'acd_niaid', 'name': 'AccessClinicalData@NIAID Dataset Schema', 'alternateName': 'acd_niaid', 'url': 'https://accessclinicaldata.niaid.nih.gov/', 'version': '2023-02-25T00:00:08Z', 'citation': {'@type': 'WebSite', 'name': 'AccessClinicalData@NIAID', 'url': 'https://accessclinicaldata.niaid.nih.gov/'}}, {'@type': 'CreativeWork', 'identifier': 'nde:Dataset', 'name': 'NIAID Data Ecosystem (NDE) Dataset Schema', 'alternateName': 'nde:Dataset', 'url': 'https://discovery.biothings.io/view/nde/', 'version': '2022-09-21', 'citation': {'@type': 'WebSite', 'name': 'NIAID Data Ecosystem (NDE) schema', 'url': 'https://discovery.biothings.io/view/nde/'}}]\n",
      "[{'@type': 'CreativeWork', 'identifier': 'bioconductor', 'name': 'Bioconductor', 'alternateName': 'bioconductor.org', 'url': 'https://www.bioconductor.org/', 'version': 'Bioc 3.15', 'citation': {'@type': 'ScholarlyArticle', 'name': 'Bioconductor: open software development for computational biology and bioinformatics', 'url': 'https://genomebiology.biomedcentral.com/articles/10.1186/gb-2004-5-10-r80'}}, {'@type': 'CreativeWork', 'identifier': 'nde:ComputationalTool', 'name': 'NIAID Data Ecosystem (NDE) ComputationalTool Schema', 'alternateName': 'nde:ComputationalTool', 'url': 'https://discovery.biothings.io/view/niaid/Dataset/', 'version': '2022-08-14', 'citation': {'@type': 'WebSite', 'name': 'NIAID Data Ecosystem (NDE) schema', 'url': 'https://discovery.biothings.io/view/nde/ComputationalTool'}}]\n",
      "[{'@type': 'CreativeWork', 'identifier': 'biotools', 'name': 'bio.tools', 'alternateName': 'ELIXIR bio.tools', 'url': 'https://bio.tools', 'version': nan, 'citation': {'@type': 'ScholarlyArticle', 'name': 'The bio.tools registry of software tools and data resources for the life sciences', 'url': 'https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1772-6'}}, {'@type': 'CreativeWork', 'identifier': 'nde:ComputationalTool', 'name': 'NIAID Data Ecosystem (NDE) ComputationalTool Schema', 'alternateName': 'nde:ComputationalTool', 'url': 'https://discovery.biothings.io/view/niaid/Dataset/', 'version': '2022-08-14', 'citation': {'@type': 'WebSite', 'name': 'NIAID Data Ecosystem (NDE) schema', 'url': 'https://discovery.biothings.io/view/nde/ComputationalTool'}}]\n",
      "[{'@type': 'CreativeWork', 'identifier': 'clinepidb', 'name': 'Clinical Epidemiology Resources', 'alternateName': 'clinepidb', 'url': 'https://clinepidb.org/ce/app/', 'version': 'ClinEpiDB 23', 'citation': {'@type': 'ScholarlyArticle', 'name': 'ClinEpiDB: an open-access clinical epidemiology database resource encouraging online exploration of complex studies.', 'url': 'https://gatesopenresearch.org/articles/3-1661/v2'}}, {'@type': 'CreativeWork', 'identifier': 'nde:Dataset', 'name': 'NIAID Data Ecosystem (NDE) Dataset Schema', 'alternateName': 'nde:Dataset', 'url': 'https://discovery.biothings.io/view/nde/Dataset/', 'version': '2022-06-09', 'citation': {'@type': 'WebSite', 'name': 'NIAID Data Ecosystem (NDE) schema', 'url': 'https://discovery.biothings.io/view/nde/Dataset'}}]\n",
      "[{'@type': 'CreativeWork', 'identifier': 'nde', 'name': 'NIAID Data Ecosystem (NDE) Schema', 'alternateName': 'nde', 'url': 'https://discovery.biothings.io/view/nde/', 'version': '2022-09-21', 'citation': {'@type': 'WebSite', 'name': 'NIAID Data Ecosystem (NDE) schema', 'url': 'https://discovery.biothings.io/view/nde/'}}, {'@type': 'CreativeWork', 'identifier': 'outbreak', 'name': 'Outbreak.info schema', 'alternateName': 'outbreak', 'url': 'https://discovery.biothings.io/view/outbreak/', 'version': '2022-09-21', 'citation': {'@type': 'WebSite', 'name': 'Outbreak.info Dataset schema', 'url': 'https://discovery.biothings.io/view/outbreak/'}}]\n",
      "[{'@type': 'CreativeWork', 'identifier': 'outbreak:Dataset', 'name': 'Outbreak.info Dataset schema', 'alternateName': 'outbreak:Dataset', 'url': 'https://discovery.biothings.io/view/outbreak/Dataset/', 'version': '2022-09-21', 'citation': {'@type': 'WebSite', 'name': 'Outbreak.info Dataset schema', 'url': 'https://discovery.biothings.io/view/outbreak/Dataset'}}, {'@type': 'CreativeWork', 'identifier': 'nde:Dataset', 'name': 'NIAID Data Ecosystem (NDE) Dataset Schema', 'alternateName': 'nde:Dataset', 'url': 'https://discovery.biothings.io/view/nde/Dataset/', 'version': '2022-09-21', 'citation': {'@type': 'WebSite', 'name': 'NIAID Data Ecosystem (NDE) schema', 'url': 'https://discovery.biothings.io/view/nde/Dataset'}}]\n",
      "[{'@type': 'CreativeWork', 'identifier': 'veupathdb', 'name': 'Eukaryotic Pathogen, Vector and Host Informatics Resource', 'alternateName': 'veupathdb', 'url': 'https://veupathdb.org/veupathdb/app/', 'version': '2022-04-20', 'citation': {'@type': 'ScholarlyArticle', 'name': 'VEuPathDB: the eukaryotic pathogen, vector and host bioinformatics resource center', 'url': 'https://doi.org/10.1093/nar/gkab929'}}, {'@type': 'CreativeWork', 'identifier': 'nde:Dataset', 'name': 'NIAID Data Ecosystem (NDE) Dataset Schema', 'alternateName': 'nde:Dataset', 'url': 'https://discovery.biothings.io/view/nde/Dataset/', 'version': '2022-06-09', 'citation': {'@type': 'WebSite', 'name': 'NIAID Data Ecosystem (NDE) schema', 'url': 'https://discovery.biothings.io/view/nde/Dataset'}}]\n",
      "[{'@type': 'CreativeWork', 'identifier': 'niaid:Dataset', 'name': 'NIAID Division of Microbiology and Infectious Diseases (DMID) Systems Biology (NIAID SysBio) Dataset Schema', 'alternateName': 'niaid:Dataset', 'url': 'https://discovery.biothings.io/view/niaid/Dataset/', 'version': '2022-06-09', 'citation': {'@type': 'WebSite', 'name': 'NIAID Data Portal', 'url': 'https://discovery.biothings.io/portal/niaid'}}, {'@type': 'CreativeWork', 'identifier': 'nde:Dataset', 'name': 'NIAID Data Ecosystem (NDE) Dataset Schema', 'alternateName': 'nde:Dataset', 'url': 'https://discovery.biothings.io/view/nde/Dataset/', 'version': '2022-09-20', 'citation': {'@type': 'WebSite', 'name': 'NIAID Data Ecosystem', 'url': 'https://docs.niaiddata.org/'}}]\n",
      "[{'@type': 'CreativeWork', 'identifier': 'vivli', 'name': 'Vivli - Center for Global Clinical Research Data', 'alternateName': 'Vivli', 'url': 'https://prod-api.vivli.org/api/', 'version': '1.0.0', 'citation': {'@type': 'VideoObject', 'name': 'How Vivli Promotes Discoverability of Partner Platforms and Repositories', 'url': 'https://youtu.be/YsX_EfdMR1Q'}}, {'@type': 'CreativeWork', 'identifier': 'nde:Dataset', 'name': 'NIAID Data Ecosystem (NDE) Dataset Schema', 'alternateName': 'nde:Dataset', 'url': 'https://discovery.biothings.io/view/nde/Dataset/', 'version': '2022-06-09', 'citation': {'@type': 'WebSite', 'name': 'NIAID Data Ecosystem (NDE) schema', 'url': 'https://discovery.biothings.io/view/nde/Dataset'}}]\n",
      "[{'@type': 'schema:CreativeWork', 'identifier': 'schema.Dataset', 'name': 'Schema.org', 'alternateName': 'sdo', 'url': 'https://schema.org/', 'version': 5.0, 'citation': {'@type': 'schema:CreativeWork', 'name': 'Schema.org Version 5.0', 'url': 'https://htmlpreview.github.io/?https://github.com/schemaorg/schemaorg/blob/main/data/releases/5.0/schema-all.html'}}, {'@type': 'schema:CreativeWork', 'identifier': 'google.Dataset', 'name': 'Google Dataset Search', 'alternateName': 'google', 'url': 'https://developers.google.com/search/docs/advanced/structured-data/dataset', 'version': nan, 'citation': {'@type': 'schema:CreativeWork', 'name': 'Google Dataset Search Guide', 'url': 'https://developers.google.com/search/docs/advanced/structured-data/dataset#guidelines'}}]\n"
     ]
    }
   ],
   "source": [
    "nb_path = os.getcwd()\n",
    "script_path = os.path.dirname(nb_path)\n",
    "#script_path = ''\n",
    "data_path = os.path.join(script_path,'crosswalks')\n",
    "export_path = os.path.join(script_path,'jsoncrosswalks')\n",
    "data_files = os.listdir(data_path)\n",
    "\n",
    "\n",
    "for filename in data_files:\n",
    "    data_file = os.path.join(data_path,filename)\n",
    "    export_file = os.path.join(export_path,filename.replace('xlsx','json').replace('xls','json'))\n",
    "    xwalkjson = convert_xls_xwalk(data_file)\n",
    "    print(xwalkjson['hasPart'])\n",
    "#    with open(export_file,'w') as outfile:\n",
    "#        jsonfile = json.dumps(xwalkjson, indent=2)\n",
    "#        outfile.write(jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1986bfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gtsueng\\Anaconda3\\envs\\outbreak\\DDE-CrossWalks\\crosswalks\\rda_schema_xref_google_Dataset.xls\n"
     ]
    }
   ],
   "source": [
    "print(data_file)\n",
    "author_object = load_authors(data_file)\n",
    "#print(author_object[0])\n",
    "funding_object = load_funding(data_file)\n",
    "#print(funding_object)\n",
    "schemaOriginList, schemaTargetList, schemaUsageList, context_dict, idlist = load_schema_objects(data_file)\n",
    "#print(schemaOriginList)\n",
    "#print(idlist)\n",
    "propdict = parse_nestedProps(data_file)\n",
    "#print(propdict)\n",
    "includedprops = generate_prop_included(data_file,idlist)\n",
    "#print(includedprops[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "666bef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     acd_niaid\n",
      "0                        title\n",
      "1                cmc_unique_id\n",
      "2                brief_summary\n",
      "3       data_availability_date\n",
      "4           most_recent_update\n",
      "5               data_available\n",
      "6                      creator\n",
      "7                   nct_number\n",
      "8                    condition\n",
      "9       clinical_trial_website\n",
      "10                publications\n",
      "11  data_available_for_request\n",
      "['nde:Dataset', 'AccessClinicalData@NIAID']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    proplist = read_excel(data_file,sheet_name='propertyList',header=0,index_col=None)\n",
    "except:\n",
    "    proplist = read_excel(data_file,sheet_name='propertyList',header=0,index_col=None,engine=\"openpyxl\")\n",
    "proplist.dropna(axis=1, how='all', inplace=True)\n",
    "same_cols = [col for col in proplist.columns if 'sameAs' in col]\n",
    "source_cols = [col for col in proplist.columns if 'sameAs' not in col]\n",
    "sourcedf = proplist[source_cols].copy()\n",
    "print(sourcedf)\n",
    "partid = [col for col in sourcedf.columns if col in idlist]\n",
    "print(idlist)\n",
    "#print(proplist)\n",
    "#tmpdict = {'@id': partid[0]}\n",
    "#sourcedf = clean_up_props(sourcedf,idlist)\n",
    "#samedf = proplist[same_cols].copy()\n",
    "#samedf.rename(columns=lambda s: s.replace(\"sameAs.\", \"\"), inplace=True)\n",
    "#partid = [col for col in samedf.columns if col in idlist]\n",
    "#print(samedf.columns)\n",
    "#print(idlist)\n",
    "#samedf = clean_up_props(samedf,idlist)\n",
    "#samedict = samedf.to_dict(orient=\"records\")\n",
    "#sourcedf['sameAs'] = samedict\n",
    "#propdictlist = sourcedf.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2857cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = ''\n",
    "data_path = os.path.join(script_path,'crosswalks')\n",
    "export_path = os.path.join(script_path,'jsoncrosswalks')\n",
    "#data_file = os.path.join(data_path,'vuepathdb.xls')\n",
    "#export_file = os.path.join(export_path,'vuepathdb.json')\n",
    "data_files = os.listdir(data_path)\n",
    "\n",
    "data_file = os.path.join(data_path,data_files[0])\n",
    "schemaOriginList, schemaTargetList, schemaUsageList, context_dict, idlist = load_schema_objects(data_file)\n",
    "schemaList = merge_schema_objects(schemaOriginList,schemaTargetList)\n",
    "print(schemaList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3111ece",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "convert_crosswalks() missing 1 required positional argument: 'export_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16252/1057840034.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#### Run the xls to json conversions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mconvert_crosswalks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscript_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: convert_crosswalks() missing 1 required positional argument: 'export_path'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import read_excel\n",
    "import os\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from src.schema_merge import *\n",
    "from collections import OrderedDict\n",
    "from src.xls_to_json import *\n",
    "from copy import deepcopy\n",
    "import openpyxl\n",
    "\n",
    "#### Update the schemas\n",
    "script_path = ''\n",
    "\n",
    "#### Run the xls to json conversions\n",
    "convert_crosswalks(script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e0fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d42c11",
   "metadata": {},
   "source": [
    "## This code converts a crosswalk table to a compliant jsonld file\n",
    "\n",
    "Note that a crosswalk table may need to be reformatted to include missing information. For example, some crosswalks will include information on the marginality of a property while others do not. If property marginality is not included, it should be included as \"unspecified\". Additionally, a crosswalk table may use a simple header to reference the schema for which the property is being compared. Whenever possible, details for that schema should be included in the schemaUsageObject (see template). \n",
    "\n",
    "Some schemas are derived by mixing and matching from other schemas. If there are properties in a schema that were derived from elsewhere, details of the schema (from which they were derived) should be included in the schemaOriginObject (see template)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83261b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262a5ff5",
   "metadata": {},
   "source": [
    "#### Expected tables and how they're used\n",
    "\n",
    "* **schemaOriginObject**: An array of metadata about a (or multiple) source schema(s). In most cases, the source schema and target schema can be treated interchangeably. HOWEVER, there are schemas which are sets of properties pulled from other schemas. In this case, the source schema should include all the schemas from which properties were pulled.\n",
    "\n",
    "* **schemaUsageObject**: An array of metadata about a (or multiple) target schema(s). In most cases, the target schema and source schema can be treated interchangeably. However, there are schemas which are sets of properties pulled from other schemas. In this case, the target schema will be the mix-n-match schema.\n",
    "\n",
    "* **propertyCrossWalk**: An array of properties from one schema, mapped to properties in another schema. Note that it is possible for a single property in schema A to map to multiple properties in schema B (and vice versa). In this case, include each property as a separate row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad568326",
   "metadata": {},
   "outputs": [],
   "source": [
    "scriptpath = \"\"\n",
    "exportpath = os.path.join(scriptpath,'crosswalks')\n",
    "schemapath = os.path.join(scriptpath,'schema')\n",
    "datapath = os.path.join(scriptpath,'templates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8034963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_list(schemaOrigin):\n",
    "    context_info = schemaOrigin[['namespace','@context']].copy()\n",
    "    context_dict = {}\n",
    "    for i in range(len(context_info)):\n",
    "        tmpnamespace = context_info.iloc[i]['namespace']\n",
    "        tmpuri = context_info.iloc[i]['@context']\n",
    "        context_dict[str(tmpnamespace)]=str(tmpuri)\n",
    "    return context_dict\n",
    "\n",
    "def load_schemaObjects(schemaOrigin):\n",
    "    originforjson = schemaOrigin[['@type','name','alternateName','url','version']].copy()\n",
    "    citationdf = schemaOrigin[['citation.@type','citation.name','citation.url']].copy()\n",
    "    citationdf.rename(columns={'citation.@type':'@type','citation.name':'name','citation.url':'url'},inplace=True)\n",
    "    citejson = citationdf.to_dict(orient='records')\n",
    "    originforjson['citation'] = [x for x in citejson]\n",
    "    originforjson['alternateNameClean'] = originforjson.apply(lambda row: deal_with_multis(row['alternateName']),axis=1)\n",
    "    originforjson.drop('alternateName',inplace=True,axis=1)\n",
    "    originforjson.rename(columns = {'alternateNameClean':'alternateName'},inplace=True)\n",
    "    schemaOriginObject = originforjson.to_dict(orient='records')\n",
    "    return schemaOriginObject\n",
    "\n",
    "def deal_with_multis(record_entry):\n",
    "    tmpdata = record_entry.split(',')\n",
    "    record_entry = tmpdata\n",
    "    return record_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc55bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['propertyCrossWalk.txt', 'schemaOriginObject.txt', 'schemaUsageObject.txt']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(datapath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b47ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'schema': 'https://schema.org/', 'dct': 'http://purl.org/dc/terms/', 'foaf': 'https://xmlns.com/foaf/spec/#term_', 'dcat': 'http://www.w3.org/ns/dcat#', 'sosa': 'https://www.w3.org/TR/vocab-ssn/#SOSA', 'prov': 'http://www.w3.org/ns/prov#', 'datacite': 'https://support.datacite.org/docs/datacite-metadata-schema-v44-properties-overview#', 'skos': 'http://www.w3.org/2004/02/skos/core#', 'dc': 'http://purl.org/dc/elements/1.1/', 'bioschemas': 'https://discovery.biothings.io/view/bioschemas/', 'bioschemastypes': 'https://discovery.biothings.io/view/bioschemastypes/', 'bioschemasdrafts': 'https://discovery.biothings.io/view/bioschemasdrafts/', 'bioschemastypesdrafts': 'https://discovery.biothings.io/view/bioschemastypesdrafts/', 'iso19115': 'https://www.iso.org/standard/53798.html#', 'spase': 'https://spase-group.org/data/model/spase-2.4.0/spase-2_4_0_xsd.html#', 'codemeta': 'https://codemeta.github.io/terms/#', 'owl': 'http://www.w3.org/2002/07/owl#'}\n",
      "{'@type': 'schema:CreativeWork', 'name': 'DCAT Application Profile for Data Portals in Europe', 'url': 'https://ec-jrc.github.io/dcat-ap-to-schema-org/#background-dcat-ap', 'version': 'working version April 2021', 'citation': {'@type': 'schema:CreativeWork', 'name': 'DCAT-AP to Schema.org Mapping, Unofficial Draft 30 April 2021', 'url': 'https://ec-jrc.github.io/dcat-ap-to-schema-org/'}, 'alternateName': ['DCAT-AP']}\n"
     ]
    }
   ],
   "source": [
    "schemaOrigin = read_csv(os.path.join(datapath,'schemaOriginObject.txt'),delimiter='\\t',header=0,index_col=0)\n",
    "schemaOriginObject = load_schemaObjects(schemaOrigin)\n",
    "\n",
    "contextlists = generate_context_list(schemaOrigin)\n",
    "print(contextlists)\n",
    "\n",
    "schemaUsage = read_csv(os.path.join(datapath,'schemaUsageObject.txt'),delimiter='\\t',header=0,index_col=0)\n",
    "schemaUsageObject = load_schemaObjects(schemaUsage)\n",
    "print(schemaUsageObject[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30c5f834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  @id         name             domainIncludes  \\\n",
      "0  google:description  description  [{'@id': 'schema:Thing'}]   \n",
      "1         google:name         name  [{'@id': 'schema:Thing'}]   \n",
      "\n",
      "              rangeIncludes                             url  \\\n",
      "0  [{'@id': 'schema:Text'}]  https://schema.org/description   \n",
      "1  [{'@id': 'schema:Text'}]         https://schema.org/name   \n",
      "\n",
      "                                            isPartOf owl:cardinality  \\\n",
      "0  {'@type': 'schema:DataDownload', 'name': 'Goog...     unspecified   \n",
      "1  {'@type': 'schema:DataDownload', 'name': 'Goog...     unspecified   \n",
      "\n",
      "           marginality            @type  \n",
      "0  minimal or required  schema:Property  \n",
      "1  minimal or required  schema:Property  \n"
     ]
    }
   ],
   "source": [
    "def lookup_schemaObject(is_partof_value, a_schema_object):\n",
    "    object_index = is_partof_value.split(':')\n",
    "    mapped_object = a_schema_object[int(object_index[1])]\n",
    "    return mapped_object\n",
    "\n",
    "def format_iri_as_id(example_iri):\n",
    "    iri_list = example_iri.split(',')\n",
    "    tmplist = []\n",
    "    for each_iri in iri_list:\n",
    "        iri_dict = {\"@id\":each_iri}\n",
    "        tmplist.append(iri_dict)\n",
    "    return tmplist\n",
    "    \n",
    "def add_type(propdf):\n",
    "    propdf['@type'] = \"schema:Property\"\n",
    "    return propdf\n",
    "\n",
    "def cleanup_domain_range(propertydf):\n",
    "    propertydf['rangeIncludes'] = propertydf.apply(lambda row: format_iri_as_id(row['rangeIncludes']), axis=1)\n",
    "    propertydf['domainIncludes'] = propertydf.apply(lambda row: format_iri_as_id(row['domainIncludes']), axis=1)\n",
    "    return propertydf\n",
    "\n",
    "propdf = read_csv(os.path.join(datapath,'propertyCrossWalk.txt'),delimiter='\\t',header=0,index_col=None)\n",
    "#print(propdf.head(n=2))\n",
    "props2map = propdf[['@id','name','domainIncludes','rangeIncludes','url',\n",
    "                    'isPartOf','owl:cardinality','marginality']].copy()\n",
    "\n",
    "props2map = add_type(props2map)\n",
    "props2map = cleanup_domain_range(props2map)\n",
    "#props2map['isPartOf'] = props2map.apply(lambda row: lookup_schemaObject(row['isPartOf'],schemaOriginObject), axis=1)\n",
    "\n",
    "#print(props2map.head(n=2))\n",
    "\n",
    "mappedprops = propdf[['sameAs.@id','sameAs.name','sameAs.domainIncludes',\n",
    "                      'sameAs.rangeIncludes','sameAs.url','sameAs.isPartOf',\n",
    "                      'sameAs.owl:cardinality','sameAs.marginality']].copy()\n",
    "mappedprops.rename(columns=lambda s: s.replace(\"sameAs.\", \"\"), inplace=True)\n",
    "\n",
    "mappedprops = add_type(mappedprops)\n",
    "mappedprops = cleanup_domain_range(mappedprops)\n",
    "mappedprops['isPartOf'] = mappedprops.apply(lambda row: lookup_schemaObject(row['isPartOf'],schemaUsageObject), axis=1)\n",
    "print(mappedprops.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc8154",
   "metadata": {},
   "outputs": [],
   "source": [
    "originforjson = schemaOrigin[['@type','name','alternateName','url','version']].copy()\n",
    "citationforjson = schemaOrigin[['citation.@type','citation.name','citation.url']].copy()\n",
    "citationforjson.rename(columns={'citation.@type':'@type','citation.name':'name','citation.url':'url'},inplace=True)\n",
    "testjson = originforjson[0:2]\n",
    "testcite = citationforjson[0:2]\n",
    "citejson = testcite.to_dict(orient='records')\n",
    "testjson['citation'] = [x for x in citejson]\n",
    "\n",
    "print(testjson)\n",
    "\n",
    "#print(testjson.to_dict(orient='records'))\n",
    "#print(testcite.to_dict(orient='records'))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def check_for_multi_cite(recordlist):\n",
    "    freq = recordlist.groupby(['@type','name','alternateName','url','version']).size().reset_index(name='counts')\n",
    "    dups = freq['name'].loc[freq['counts']>1].tolist()\n",
    "    nondups = recordlist.loc[~recordlist['name'].isin(dups)].copy()\n",
    "    for eachname in dups:\n",
    "        recordsubset = recordlist.loc[recordlist['name']==eachname]\n",
    "        citelist = tmprecords['citation'].tolist()\n",
    "        tmprecord = recordsubset.drop_duplicates(subset=['@type','name','alternateName','url','version'], keep='first').copy()\n",
    "        tmprecord['citation']=citelist\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73832875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
